import csv
import hashlib
import logging
import os.path
from datetime import datetime
from pprint import pprint

from dateutil.parser import parse
from django import forms
from django.contrib.auth.mixins import UserPassesTestMixin, LoginRequiredMixin
from django.core.files.base import ContentFile
from django.db.models import Subquery, OuterRef, Max, F, Value, Prefetch, ForeignKey, Q, IntegerField, Count
from django.db.models.functions import Left, Coalesce, Substr, Length, Cast
from django.http import Http404, JsonResponse, HttpResponse
from django.shortcuts import get_object_or_404, render, redirect
from django.template.loader import render_to_string
from django.urls import reverse_lazy
from django.utils import timezone
from django.utils.timezone import make_aware
from django.views import View
from django.contrib import messages
from django.views.generic import DetailView, ListView, CreateView, UpdateView, DeleteView
from django.core.paginator import Paginator

from app_core.models import KnowledgeBase
from app_parsers.forms import TestParseForm, BulkParseForm, ParserDynamicConfigForm
from app_parsers.models import TestParser, TestParseReport, MainParser
from app_parsers.tasks import test_single_url, parse_urls_task
from app_parsers.services.parsers.dispatcher import WebParserDispatcher
from app_sources.content_models import URLContent, RawContent, CleanedContent, ContentStatus
from app_sources.forms import CloudStorageForm, ContentRecognizerForm, CleanedContentEditorForm, \
    NetworkDocumentStatusUpdateForm
from app_sources.models import HierarchicalContextMixin
from app_sources.report_models import CloudStorageUpdateReport, WebSiteUpdateReport, ReportStatus
from app_sources.source_models import NetworkDocument, URL, SourceStatus
from app_sources.storage_models import CloudStorage, Storage, LocalStorage, WebSite, URLBatch
from app_sources.storage_views import StoragePermissionMixin
from app_sources.tasks import process_cloud_files
from recognizers.dispatcher import ContentRecognizerDispatcher
from utils.tasks import get_task_status

logger = logging.getLogger(__name__)


class DocumentPermissionMixin(UserPassesTestMixin):
    """
    Mixin –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø—Ä–∞–≤ –¥–æ—Å—Ç—É–ø–∞ –∫ –î–æ–∫—É–º–µ–Ω—Ç—É:
    –¥–æ—Å—Ç—É–ø —Ä–∞–∑—Ä–µ—à—ë–Ω —Ç–æ–ª—å–∫–æ –≤–ª–∞–¥–µ–ª—å—Ü—É —Å–≤—è–∑–∞–Ω–Ω–æ–π –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π (KnowledgeBase) –∏–ª–∏ —Å—É–ø–µ—Ä–ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é.
    """

    def test_func(self):
        if self.request.user.is_superuser:
            return True
        document = self.get_object()
        storage = getattr(document, "storage", None)
        if not storage:
            return False
        kb = getattr(storage, "knowledge_base", None)
        return kb and kb.owner == self.request.user


class CloudStorageDetailView(LoginRequiredMixin, StoragePermissionMixin, DetailView):
    """–î–µ—Ç–∞–ª—å–Ω—ã–π –ø—Ä–æ—Å–º–æ—Ç—Ä –æ–±—ä–µ–∫—Ç–∞ –º–æ–¥–µ–ª–∏ –û–±–ª–∞—á–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ"""
    model = CloudStorage

    def get(self, request, *args, **kwargs):
        self.object = self.get_object()
        context = self.get_context_data()

        if request.headers.get("x-requested-with") == "XMLHttpRequest":
            html = render_to_string(
                "app_sources/include/network_documents_page.html",
                context,
                request=request
            )
            return JsonResponse({"html": html})

        return self.render_to_response(context)

    def get_context_data(self, **kwargs):
        network_storage = self.object
        context = super().get_context_data()

        # –æ—Ç—á–µ—Ç—ã –ø–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è–º
        update_report_count = CloudStorageUpdateReport.objects.filter(storage=network_storage).count()
        context["update_report_count"] = update_report_count
        # –ü–µ—Ä–µ–¥–∞—ë–º —Ç—Ä–∏ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö –æ—Ç—á—ë—Ç–∞
        update_reports_last = (CloudStorageUpdateReport.objects
                               .select_related("author")
                               .filter(storage=network_storage)
                               .defer("storage", "content", "running_background_tasks")
                               .order_by("-created_at")[:3])
        context["update_reports_last"] = update_reports_last

        source_statuses = [
            (status.value, status.display_name) for status in SourceStatus
        ]

        filters = {
            "status": source_statuses
        }

        sorting_list = [
            ("-created_at", "–¥–∞—Ç–∞ —Å–æ–∑–¥–∞–Ω–∏—è –ø–æ –≤–æ–∑—Ä–∞—Å—Ç–∞–Ω–∏—é"),
            ("created_at", "–¥–∞—Ç–∞ —Å–æ–∑–¥–∞–Ω–∏—è –ø–æ —É–±—ã–≤–∞–Ω–∏—é"),
            ("-title", "–∏–º—è –ø–æ –≤–æ–∑—Ä–∞—Å—Ç–∞–Ω–∏—é"),
            ("title", "–∏–º—è –ø–æ —É–±—ã–≤–∞–Ω–∏—é"),
            ("-url", "url –ø–æ –≤–æ–∑—Ä–∞—Å—Ç–∞–Ω–∏—é"),
            ("url", "url –ø–æ —É–±—ã–≤–∞–Ω–∏—é"),
        ]

        # –ü–æ–ª—É—á–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ–∏—Å–∫–∞ –∏ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –∏–∑ –∑–∞–ø—Ä–æ—Å–∞
        search_query = self.request.GET.get("search", "").strip()
        status_filter = self.request.GET.getlist("status", None)
        sorting = self.request.GET.get("sorting", None)

        network_documents = network_storage.network_documents.order_by("title")

        if search_query:
            network_documents = network_documents.filter(
                Q(title__icontains=search_query) |
                Q(url__icontains=search_query) |
                Q(description__icontains=search_query)
            )

        if status_filter:
            valid_statuses = [status.value for status in SourceStatus]
            # –û—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
            status_filter = [s for s in status_filter if s in valid_statuses]
            if status_filter:
                network_documents = network_documents.filter(status__in=status_filter)

        if sorting:
            valid_sorting = [value for value, name in sorting_list]
            if sorting in valid_sorting:
                network_documents = network_documents.order_by(sorting)

        rawcontent_qs = RawContent.objects.filter(
            status=ContentStatus.READY.value
        ).select_related(
            'cleanedcontent'
        ).order_by("-created_at")[:1]

        # Prefetch rawcontent_set ‚Üí –≤ each networkdocument.related_rawcontents –±—É–¥–µ—Ç —Å–ø–∏—Å–æ–∫ –∏–∑ 0 –∏–ª–∏ 1
        network_documents = network_documents.select_related(
            "report__storage", "storage"
        ).prefetch_related(
            Prefetch('rawcontent_set', queryset=rawcontent_qs, to_attr='related_rawcontents')
        ).annotate(
            rawcontent_total_count=Count('rawcontent')
        )

        paginator = Paginator(network_documents, 3)
        page_number = self.request.GET.get("page")
        page_obj = paginator.get_page(page_number)

        # –ù–∞–∑–Ω–∞—á–∞–µ–º —è–≤–Ω–æ (0 –∏–ª–∏ 1 —ç–ª–µ–º–µ–Ω—Ç)
        for doc in page_obj.object_list:
            doc.active_rawcontent = doc.related_rawcontents[0] if doc.related_rawcontents else None

        # –§–æ—Ä–º–∏—Ä—É–µ–º query string –±–µ–∑ page
        query_params = self.request.GET.copy()
        query_params.pop('page', None)
        paginator_query = query_params.urlencode()
        if paginator_query:
            paginator_query += '&'

        context["page_obj"] = page_obj
        context["paginator_query"] = paginator_query
        context["paginator"] = paginator
        context["network_documents"] = page_obj.object_list
        context["is_paginated"] = page_obj.has_other_pages()
        context["search_query"] = search_query
        context["status_filter"] = status_filter
        context["source_statuses"] = source_statuses
        context["filters"] = filters
        context["sorting_list"] = sorting_list
        return context


class CloudStorageListView(LoginRequiredMixin, ListView):
    """–°–ø–∏—Å–∫–æ–≤—ã–π –ø—Ä–æ—Å–º–æ—Ç—Ä –æ–±—ä–µ–∫—Ç–æ–≤ –º–æ–¥–µ–ª–∏ –û–±–ª–∞—á–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ"""
    model = CloudStorage

    def get_queryset(self):
        queryset = super().get_queryset()
        if self.request.user.is_superuser:
            return queryset
        queryset = queryset.filter(soft_deleted_at__isnull=True).filter(owners=self.request.user)
        return queryset


class CloudStorageCreateView(LoginRequiredMixin, StoragePermissionMixin, CreateView):
    """–°–æ–∑–¥–∞–Ω–∏–µ –æ–±—ä–µ–∫—Ç–∞ –º–æ–¥–µ–ª–∏ –û–±–ª–∞—á–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ"""
    model = CloudStorage
    form_class = CloudStorageForm

    def get_initial(self):
        """–ü—Ä–µ–¥–∑–∞–ø–æ–ª–Ω–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –¥–ª—è —É–¥–æ–±—Å—Ç–≤–∞ –ø—Ä–∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏"""
        return {
            "name": "–û–±–ª–∞–∫–æ –ê–∫–∞–¥–µ–º–∏–∏ –î–ü–û",
            "api_type": "webdav",
            "url": "https://cloud.academydpo.org/public.php/webdav/",
            "root_path": "documents/",
            "auth_type": "token",
            "token": "rqJWt7LzPGKcyNw"
        }

    def dispatch(self, request, *args, **kwargs):
        """–°–æ—Ö—Ä–∞–Ω—è–µ–º knowledge_base –¥–ª—è –¥–∞–ª—å–Ω–µ–π—à–µ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è"""
        self.knowledge_base = get_object_or_404(KnowledgeBase, pk=kwargs['kb_pk'])
        return super().dispatch(request, *args, **kwargs)

    def form_valid(self, form):
        """–£—Å—Ç–∞–Ω–æ–≤–∫–∞ —Å–≤—è–∑–∏ —Å –±–∞–∑–æ–π –∑–Ω–∞–Ω–∏–π –ø–µ—Ä–µ–¥ –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π"""
        kb_pk = self.kwargs.get("kb_pk")
        if not kb_pk:
            form.add_error(None, "–ù–µ –ø–µ—Ä–µ–¥–∞–Ω ID –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π")
            return self.form_invalid(form)

        form.instance.kb = self.knowledge_base
        form.instance.author = self.request.user
        return super().form_valid(form)

    def get_form(self, form_class=None):
        form = super().get_form(form_class)
        kb_pk = self.kwargs.get("kb_pk")
        if kb_pk:
            form.instance.kb_id = kb_pk
        form.instance.author = self.request.user
        return form

    # def get_context_data(self, **kwargs):
    #     """–î–æ–±–∞–≤–∏—Ç—å ID –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç (–µ—Å–ª–∏ –Ω—É–∂–Ω–æ –¥–ª—è —à–∞–±–ª–æ–Ω–∞)"""
    #     context = super().get_context_data(**kwargs)
    #     context['kb_pk'] = self.kwargs.get('kb_pk')
    #     return context


class CloudStorageUpdateView(LoginRequiredMixin, UpdateView):
    model = CloudStorage
    fields = ("name", "description")

    def get_form(self, form_class=None):
        form = super().get_form(form_class)
        form.fields["name"].widget.attrs["class"] = "form-control"
        form.fields["description"].widget = forms.Textarea(attrs={"rows": 4, "class": "form-control"})
        return form


class CloudStorageDeleteView(LoginRequiredMixin, DeleteView):
    model = CloudStorage
    success_url = reverse_lazy("sources:cloudstorage_list")


class CloudStorageSyncView(View):
    """
    –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –æ–±–ª–∞—á–Ω–æ–≥–æ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞: –ø–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ —Ñ–∞–π–ª–æ–≤, —Å–æ–∑–¥–∞–Ω–∏–µ –æ—Ç—á—ë—Ç–∞, –∑–∞–ø—É—Å–∫ —Ñ–æ–Ω–æ–≤–æ–π –∑–∞–¥–∞—á–∏.
    """

    def post(self, request, pk):

        cloud_storage = get_object_or_404(CloudStorage, pk=pk)
        synced_documents = request.POST.getlist("synced_documents")
        logger.info(f"–ù–∞—á–∞–ª–æ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞: {cloud_storage.name}, –∑–∞–ø—É—â–µ–Ω–∞ {request.user}")
        storage_update_report = CloudStorageUpdateReport.objects.create(storage=cloud_storage, author=self.request.user)

        try:
            task = process_cloud_files.delay(
                files=synced_documents,
                update_report_pk=storage_update_report.pk,
            )

            storage_update_report.running_background_tasks[task.id] = "–°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è —Ñ–∞–π–ª–æ–≤"
            storage_update_report.save(update_fields=["running_background_tasks", ])

            return render(request, 'app_sources/cloudstorage_progress_report.html', {
                'task_id': task.task_id,
                'cloudstorage': cloud_storage,
                "next_step_url": storage_update_report.get_absolute_url()
            })

        except Exception as e:
            logger.exception(f"–û—à–∏–±–∫–∞ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞: {cloud_storage.name}, –∑–∞–ø—É—â–µ–Ω–∞ {request.user},"
                             f" –æ—Ç—á–µ—Ç [CloudStorageUpdateReport id {storage_update_report.pk}]")
            storage_update_report.content.setdefault("errors", []).append(str(e))
            storage_update_report.save()
            return render(request, 'app_sources/sync_result.html', {
                'result': {'error': f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Ñ–∞–π–ª–æ–≤: {e}"},
                'cloud_storage': cloud_storage
            })


class CloudStorageUpdateReportDetailView(LoginRequiredMixin, DetailView):
    """–î–µ—Ç–∞–ª—å–Ω—ã–π –ø—Ä–æ—Å–º–æ—Ç—Ä –æ—Ç—á—ë—Ç–∞ –æ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏ –æ–±–ª–∞—á–Ω–æ–≥–æ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞"""
    model = CloudStorageUpdateReport

    def get_context_data(self, **kwargs):
        context = super().get_context_data(**kwargs)
        report = self.object
        # –ü—Ä–µ—Ñ–µ—Ç—á–∏–º –æ–¥–∏–Ω RawContent –Ω–∞ –∫–∞–∂–¥—ã–π NetworkDocument, –µ—Å–ª–∏ –æ–Ω –µ—Å—Ç—å
        rawcontent_qs = RawContent.objects.filter(report=report)

        # Prefetch rawcontent_set ‚Üí –≤ each networkdocument.related_rawcontents –±—É–¥–µ—Ç —Å–ø–∏—Å–æ–∫ –∏–∑ 0 –∏–ª–∏ 1
        network_documents = report.networkdocument_set.select_related("report__storage", "storage").prefetch_related(
            Prefetch('rawcontent_set', queryset=rawcontent_qs, to_attr='related_rawcontents')
        )
        # –ù–∞–∑–Ω–∞—á–∞–µ–º —è–≤–Ω–æ (0 –∏–ª–∏ 1 —ç–ª–µ–º–µ–Ω—Ç)
        for doc in network_documents:
            doc.created_rawcontent = doc.related_rawcontents[0] if doc.related_rawcontents else None

        context["created_network_documents"] = network_documents

        # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –ø–æ –∏—Å–ø–æ–ª–Ω—è–µ–º—ã–º —Ñ–æ–Ω–æ–≤—ã–º –∑–∞–¥–∞—á–∞–º Celery
        running_background_tasks = report.running_background_tasks
        task_context = []
        for task_id, task_name in running_background_tasks.items():
            task_context.append(
                {
                    "task_name": task_name,
                    "task_id": task_id,
                    "report": get_task_status(task_id)
                }
            )
        context['task_context'] = task_context
        return context


class CloudStorageUpdateReportListView(LoginRequiredMixin, ListView):
    """–°–ø–∏—Å–∫–æ–≤–æ–µ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –æ—Ç—á–µ—Ç–æ–≤ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–π –ø–æ –æ–±–ª–∞—á–Ω–æ–º—É —Ö—Ä–∞–Ω–∏–ª–∏—â—É"""
    model = CloudStorageUpdateReport
    context_object_name = "reports"
    paginate_by = 10

    def get_queryset(self):
        storage_pk = self.request.GET.get("storage")
        if not storage_pk:
            return CloudStorageUpdateReport.objects.none()

        try:
            storage = CloudStorage.objects.select_related("kb").get(pk=storage_pk)
        except CloudStorage.DoesNotExist:
            return CloudStorageUpdateReport.objects.none()
        if not storage.kb.owners.filter(pk=self.request.user.pk).exists():
            return CloudStorageUpdateReport.objects.none()

        queryset = (CloudStorageUpdateReport.objects
                    .filter(storage=storage)
                    .select_related("author")
                    .defer("storage", "content", "running_background_tasks")
                    .order_by("-created_at")[:3])
        return queryset


class WebSiteUpdateReportDetailView(LoginRequiredMixin, DetailView):
    """–î–µ—Ç–∞–ª—å–Ω—ã–π –ø—Ä–æ—Å–º–æ—Ç—Ä –æ—Ç—á—ë—Ç–∞ –æ –ø–∞—Ä—Å–∏–Ω–≥–µ —Å–∞–π—Ç–∞"""
    model = WebSiteUpdateReport

    def get_context_data(self, **kwargs):
        context = super().get_context_data(**kwargs)
        report = self.object
        new_urls_id = self.object.content.get("result", {}).get("new_urls")
        # new_urls = URL.objects.prefetch_related("urlcontent_set").filter(pk__in=new_urls_id).annotate(
        #     body_preview=Subquery(
        #         URLContent.objects.filter(url=OuterRef("pk"))
        #         .order_by("-created_at")  # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ –ø–æ—Å–ª–µ–¥–Ω–µ–π –∑–∞–ø–∏—Å–∏
        #         .values("body")[:1]  # –ë–µ—Ä—ë–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—É—é –∑–∞–ø–∏—Å—å
        #     ),
        #     body_preview_100=Left("body_preview", 100)  # –û–±—Ä–µ–∑–∞–µ–º –¥–æ 100 —Å–∏–º–≤–æ–ª–æ–≤
        # )
        new_urls = URLContent.objects.filter(report=self.object).select_related("url").annotate(
            max_created_at=Subquery(
                URLContent.objects.filter(url=OuterRef("url"))
                .values("url")
                .annotate(max_created=Max("created_at"))
                .values("max_created")[:1]
            ),
            body_preview_301=Coalesce(Substr("body", 1, 301), Value("")),
            url_pk=F("url_id"),
            url_str=F("url__url"),
        ).filter(created_at=F("max_created_at"))

        # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –ø–æ –∏—Å–ø–æ–ª–Ω—è–µ–º—ã–º —Ñ–æ–Ω–æ–≤—ã–º –∑–∞–¥–∞—á–∞–º Celery
        running_background_tasks = report.running_background_tasks
        task_context = []
        for task_id, task_name in running_background_tasks.items():
            task_context.append(
                {
                    "task_name": task_name,
                    "task_id": task_id,
                    "report": get_task_status(task_id)
                }
            )
        context['task_context'] = task_context
        context['new_urls'] = new_urls
        return context


#
# class NetworkDocumentsMassCreateView(LoginRequiredMixin, View):
#     """
#     –°–æ–∑–¥–∞–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ (NetworkDocument) –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ—Ç—á—ë—Ç–∞ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏ (CloudStorageUpdateReport).
#     """
#
#     def post(self, request, pk):
#         selected_ids = [i for i in request.POST.getlist("file_ids") if i.strip()]
#         if not selected_ids:
#             # TODO message
#             return redirect(reverse_lazy("sources:cloudstorageupdatereport_detail", args=[pk]))
#
#         update_report = get_object_or_404(CloudStorageUpdateReport, pk=pk)
#         new_files = update_report.content.get("result", {}).get("new_files", [])
#
#         new_files = [file for file_id, file in new_files.items() if file_id in selected_ids]
#
#         # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã, –∫–æ—Ç–æ—Ä—ã–µ —É–∂–µ –µ—Å—Ç—å –≤ –±–∞–∑–µ –¥–ª—è –¥–∞–Ω–Ω–æ–≥–æ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞
#         db_documents = NetworkDocument.objects.filter(storage=update_report.storage)
#         existing_urls = set(db_documents.values_list("url", flat=True))
#         new_urls = {f["url"] for f in new_files}
#
#         # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã –ø–æ URL
#         duplicates = existing_urls & new_urls
#
#         bulk_container = []
#         # –§–æ—Ä–º–∏—Ä—É–µ–º –æ–±—ä–µ–∫—Ç—ã –¥–ª—è –º–∞—Å—Å–æ–≤–æ–≥–æ —Å–æ–∑–¥–∞–Ω–∏—è, –ø—Ä–æ–ø—É—Å–∫–∞—è –¥—É–±–ª–∏–∫–∞—Ç—ã
#         for f in new_files:
#             if f["url"] in duplicates:
#                 f["process_status"] = "already_exists"
#                 continue
#             try:
#                 remote_updated = parse(f.get("last_modified", ''))
#             except Exception:
#                 remote_updated = None
#             bulk_container.append(NetworkDocument(
#                 storage=update_report.storage,
#                 title=f["file_name"],
#                 path=f["path"],
#                 file_id=f["file_id"],
#                 size=f["size"],
#                 url=f["url"],
#                 remote_updated=remote_updated,
#                 synchronized_at=timezone.now(),
#             ))
#
#         if bulk_container:
#             # –°–æ–∑–¥–∞—ë–º –≤—Å–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –æ–¥–Ω–∏–º –∑–∞–ø—Ä–æ—Å–æ–º
#             created_docs = NetworkDocument.objects.bulk_create(bulk_container)
#             created_ids = [doc.id for doc in created_docs]
#
#             update_report.content.setdefault("created_docs", []).extend(created_ids)
#
#             # –ò–Ω–¥–µ–∫—Å –¥–ª—è –ø—Ä–æ—Ö–æ–¥–∞ –ø–æ —Å–æ–∑–¥–∞–Ω–Ω—ã–º –¥–æ–∫—É–º–µ–Ω—Ç–∞–º
#             created_doc_index = 0
#
#             for f in new_files:
#                 if f.get("process_status") == "already_exists":
#                     # –î—É–±–ª–∏–∫–∞—Ç—ã –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
#                     continue
#                 # –û—Ç–º–µ—á–∞–µ–º –∫–∞–∫ —Å–æ–∑–¥–∞–Ω–Ω—ã–µ
#                 f["process_status"] = "created"
#                 # –ü—Ä–∏–≤—è–∑—ã–≤–∞–µ–º id —Å–æ–∑–¥–∞–Ω–Ω–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –∫ —Ñ–∞–π–ª—É
#                 f["doc_id"] = created_docs[created_doc_index].id
#                 created_doc_index += 1
#
#             update_report.content["current_status"] = "Documents successfully created, download content in progress..."
#             update_report.save(update_fields=["content"])
#
#             # –ó–∞–ø—É—Å–∫–∞–µ–º —Ñ–æ–Ω–æ–≤—É—é –∑–∞–¥–∞—á—É –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è –∏ —Å–æ–∑–¥–∞–Ω–∏—è raw content
#             task = download_and_create_raw_content_parallel.delay(
#                 document_ids=created_ids,
#                 update_report_id=update_report.pk,
#                 author=request.user
#             )
#             update_report.running_background_tasks[task.id] = "–ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ —Ñ–∞–π–ª–æ–≤ —Å –æ–±–ª–∞—á–Ω–æ–≥–æ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞"
#             update_report.save(update_fields=["running_background_tasks"])
#
#         return redirect(reverse_lazy("sources:cloudstorageupdatereport_detail", args=[pk]))
#
#
# class NetworkDocumentsMassUpdateView(LoginRequiredMixin, View):
#     pass


class NetworkDocumentListView(LoginRequiredMixin, ListView):
    """–°–ø–∏—Å–∫–æ–≤—ã–π –ø—Ä–æ—Å–º–æ—Ç—Ä –æ–±—ä–µ–∫—Ç–æ–≤ –º–æ–¥–µ–ª–∏ –°–µ—Ç–µ–≤–æ–π –¥–æ–∫—É–º–µ–Ω—Ç NetworkDocument"""
    model = NetworkDocument


class NetworkDocumentDetailView(LoginRequiredMixin, DocumentPermissionMixin, HierarchicalContextMixin, DetailView):
    """–î–µ—Ç–∞–ª—å–Ω—ã–π –ø—Ä–æ—Å–º–æ—Ç—Ä –æ–±—ä–µ–∫—Ç–∞ –º–æ–¥–µ–ª–∏ –°–µ—Ç–µ–≤–æ–π –¥–æ–∫—É–º–µ–Ω—Ç NetworkDocument (—Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π –ø—Ä–∞–≤ –¥–æ—Å—Ç—É–ø–∞)"""
    model = NetworkDocument
    rawcontent_set = Prefetch(
        "rawcontent_set",
        queryset=RawContent.objects
        .select_related("report", "author")
        .prefetch_related("cleanedcontent", "cleanedcontent__author")

    )
    queryset = (NetworkDocument.objects.select_related("storage", "storage__kb", "report", )
                .prefetch_related(rawcontent_set, "tasks"))


class NetworkDocumentUpdateView(LoginRequiredMixin, DocumentPermissionMixin, UpdateView):
    """–†–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –æ–±—ä–µ–∫—Ç–∞ –º–æ–¥–µ–ª–∏ –°–µ—Ç–µ–≤–æ–π –¥–æ–∫—É–º–µ–Ω—Ç NetworkDocument (—Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π –ø—Ä–∞–≤ –¥–æ—Å—Ç—É–ø–∞)"""
    model = NetworkDocument
    fields = ["title", "status", "output_format", "description"]


class NetworkDocumentStatusUpdateView(LoginRequiredMixin, DocumentPermissionMixin, UpdateView):
    """–ò–∑–º–µ–Ω–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞ –æ–±—ä–µ–∫—Ç–∞ –º–æ–¥–µ–ª–∏ –°–µ—Ç–µ–≤–æ–π –¥–æ–∫—É–º–µ–Ω—Ç NetworkDocument (—Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π –ø—Ä–∞–≤ –¥–æ—Å—Ç—É–ø–∞)"""
    model = NetworkDocument
    form_class = NetworkDocumentStatusUpdateForm
    template_name = "app_sources/networkdocument_status_update_form.html"

    def post(self, request, *args, **kwargs):
        pk = self.kwargs["pk"]
        instance = self.get_object()
        status_form = NetworkDocumentStatusUpdateForm(request.POST, instance=instance)
        if status_form.is_valid():
            # TODO —Å–æ–∑–¥–∞–Ω–∏–µ –∑–∞–¥–∞—á–∏ –Ω–∞ –∏–∑–º–µ–Ω–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ —Å—Ç–∞—Ç—É—Å–∞
            status_form.save()
        return redirect(reverse_lazy("sources:networkdocument_detail", kwargs={"pk": pk}))


class LocalStorageListView(LoginRequiredMixin, ListView):
    """–°–ø–∏—Å–∫–æ–≤—ã–π –ø—Ä–æ—Å–º–æ—Ç—Ä –æ–±—ä–µ–∫—Ç–æ–≤ –º–æ–¥–µ–ª–∏ –õ–æ–∫–∞–ª—å–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ"""
    model = LocalStorage

    def get_queryset(self):
        queryset = super().get_queryset()
        if self.request.user.is_superuser:
            return queryset
        queryset = queryset.filter(soft_deleted_at__isnull=True).filter(owners=self.request.user)
        return queryset


class LocalStorageDetailView(LoginRequiredMixin, StoragePermissionMixin, DetailView):
    """–î–µ—Ç–∞–ª—å–Ω—ã–π –ø—Ä–æ—Å–º–æ—Ç—Ä –æ–±—ä–µ–∫—Ç–∞ –º–æ–¥–µ–ª–∏ –õ–æ–∫–∞–ª—å–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ (—Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π –ø—Ä–∞–≤ –¥–æ—Å—Ç—É–ø–∞)"""
    model = LocalStorage


class LocalStorageCreateView(LoginRequiredMixin, StoragePermissionMixin, CreateView):
    """–°–æ–∑–¥–∞–Ω–∏–µ –æ–±—ä–µ–∫—Ç–∞ –º–æ–¥–µ–ª–∏ –õ–æ–∫–∞–ª—å–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ"""
    model = LocalStorage
    fields = "__all__"


class WebSiteDetailView(LoginRequiredMixin, StoragePermissionMixin, HierarchicalContextMixin, DetailView):
    """–î–µ—Ç–∞–ª—å–Ω—ã–π –ø—Ä–æ—Å–º–æ—Ç—Ä –æ–±—ä–µ–∫—Ç–∞ –º–æ–¥–µ–ª–∏ –í–µ–±—Å–∞–π—Ç (—Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π –ø—Ä–∞–≤ –¥–æ—Å—Ç—É–ø–∞)"""
    model = WebSite
    queryset = (WebSite.objects.select_related("author", "mainparser__author")
                .prefetch_related("test_parsers__author", "reports__author"))

    @staticmethod
    def parse_date_param(param):
        try:
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º ISO-–¥–∞—Ç—É "YYYY-MM-DD" ‚Üí datetime + timezone
            return make_aware(datetime.strptime(param, "%Y-%m-%d"))
        except (ValueError, TypeError):
            return None

    def get(self, request, *args, **kwargs):
        self.object = self.get_object()
        context = self.get_context_data()

        if request.headers.get("x-requested-with") == "XMLHttpRequest":
            html = render_to_string(
                "app_sources/include/url_list_page.html",
                context,
                request=request
            )
            return JsonResponse({"html": html})

        return self.render_to_response(context)

    def get_context_data(self, **kwargs):
        context = super().get_context_data(**kwargs)
        website = self.object

        available_tags = website.tags

        source_statuses = [(status.value, status.display_name) for status in SourceStatus]
        filters = {"status": source_statuses}

        sorting_list = [
            ("-created_at", "–¥–∞—Ç–∞ —Å–æ–∑–¥–∞–Ω–∏—è –ø–æ –≤–æ–∑—Ä–∞—Å—Ç–∞–Ω–∏—é"),
            ("created_at", "–¥–∞—Ç–∞ —Å–æ–∑–¥–∞–Ω–∏—è –ø–æ —É–±—ã–≤–∞–Ω–∏—é"),
            ("-title", "–∏–º—è –ø–æ –≤–æ–∑—Ä–∞—Å—Ç–∞–Ω–∏—é"),
            ("title", "–∏–º—è –ø–æ —É–±—ã–≤–∞–Ω–∏—é"),
            ("-url", "url –ø–æ –≤–æ–∑—Ä–∞—Å—Ç–∞–Ω–∏—é"),
            ("url", "url –ø–æ —É–±—ã–≤–∞–Ω–∏—é"),
        ]

        standard_range_list = {
            "–¥–∞—Ç–∞ —Å–æ–∑–¥–∞–Ω–∏—è": {
                "type": "date",
                "pairs": (
                    ("created_at__gte", "—Å"),
                    ("created_at__lte", "–ø–æ"),
                ),
            }
        }

        nonstandard_range_list = {
            "–¥–ª–∏–Ω–∞ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ (—Å–∏–º–≤–æ–ª–æ–≤)": {
                "annotations": {"urlcontent__body_length": Length("urlcontent__body")},
                "type": "number",
                "pairs": (
                    ("urlcontent__body_length__gte", "–æ—Ç"),
                    ("urlcontent__body_length__lte", "–¥–æ"),
                ),
            },
        }

        request_get = self.request.GET
        search_query = request_get.get("search", "").strip()
        status_filter = request_get.getlist("status", None)
        sorting = request_get.get("sorting", None)
        tags_filter = request_get.getlist("tags", None)

        urls = website.url_set.select_related("report", "report__author").all()

        # üîç –ü–æ–∏—Å–∫
        if search_query:
            urls = urls.filter(
                Q(title__icontains=search_query) | Q(url__icontains=search_query)
            )

        # ‚úÖ –°—Ç–∞—Ç—É—Å—ã
        if status_filter:
            valid_statuses = [status.value for status in SourceStatus]
            filtered_statuses = [s for s in status_filter if s in valid_statuses]
            if filtered_statuses:
                urls = urls.filter(status__in=filtered_statuses)

        # üè∑ –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ —Ç–µ–≥–∞–º

        # –í–µ—Ä—Å–∏—è –¥–ª—è PostgreSQL
        # if tags_filter:
        #     # –§–∏–ª—å—Ç—Ä—É–µ–º URL, —É –∫–æ—Ç–æ—Ä—ã—Ö –µ—Å—Ç—å URLContent —Å —É–∫–∞–∑–∞–Ω–Ω—ã–º–∏ —Ç–µ–≥–∞–º–∏
        #     urls = urls.filter(
        #         urlcontent__tags__contains=tags_filter
        #     ).distinct()

        if tags_filter:
            # –ü–æ–ª—É—á–∞–µ–º ID –≤—Å–µ—Ö URLContent, –≥–¥–µ tags —Å–æ–¥–µ—Ä–∂–∞—Ç —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω —Ç–µ–≥ –∏–∑ tags_filter
            urlcontent_ids = URLContent.objects.filter(
                url__site=website
            ).values_list("id", "tags")
            matching_url_ids = set()
            for uc_id, tags in urlcontent_ids:
                if tags and any(tag in tags for tag in tags_filter):
                    url_id = URLContent.objects.get(id=uc_id).url_id
                    matching_url_ids.add(url_id)
            urls = urls.filter(id__in=matching_url_ids).distinct()

        # üìÖ –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –¥–∏–∞–ø–∞–∑–æ–Ω (–¥–∞—Ç—ã)
        standard_range_query = {}
        for group in standard_range_list.values():
            for param_key, _ in group["pairs"]:
                raw_value = request_get.get(param_key)
                if raw_value and raw_value.strip():
                    aware_date = self.parse_date_param(raw_value)
                    if aware_date:
                        standard_range_query[param_key] = aware_date
        if standard_range_query:
            urls = urls.filter(**standard_range_query)

        # üîß –ê–Ω–Ω–æ—Ç–∞—Ü–∏–∏ + –Ω–µ—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –¥–∏–∞–ø–∞–∑–æ–Ω (—á–∏—Å–ª–æ–≤—ã–µ)
        combined_annotations = {}
        nonstandard_range_query = {}
        for item in nonstandard_range_list.values():
            item_annotations = item.get("annotations", {})
            should_add_annotation = False

            for param_key, _ in item["pairs"]:
                val = request_get.get(param_key)
                if val is not None and val.strip() != "":
                    try:
                        if item.get("type") == "number":
                            int_val = int(val.strip())
                            nonstandard_range_query[param_key] = int_val
                        else:
                            nonstandard_range_query[param_key] = val.strip()
                        should_add_annotation = True
                    except ValueError:
                        # –ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ ‚Äî –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
                        pass

            if should_add_annotation:
                combined_annotations.update(item_annotations)

        if combined_annotations:
            urls = urls.annotate(**combined_annotations)
        if nonstandard_range_query:
            urls = urls.filter(**nonstandard_range_query)

        # ‚Üï –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞
        valid_sorting = [value for value, _ in sorting_list]
        if sorting in valid_sorting:
            urls = urls.order_by(sorting)
        else:
            urls = urls.order_by("title")

        # TODO –ø–æ—Ç–æ–º —Ä–∞—Å–∫–æ–º–º–µ–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å –∏ —É–±—Ä–∞—Ç—å –±–µ–∑ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ STATUS
        # url_content_qs = URLContent.objects.filter(
        #     status=ContentStatus.READY.value
        # ).order_by("-created_at")[:1]
        # url_content_qs = URLContent.objects.order_by("-created_at")[:1]
        #
        # urls = urls.select_related("report__storage", "site").prefetch_related(
        #     Prefetch("urlcontent_set", queryset=url_content_qs, to_attr="related_urlcontents")
        # ).annotate(
        #     urlcontent_total_count=Count("urlcontent")
        # )
        #
        # # –ü–æ–¥–∑–∞–ø—Ä–æ—Å –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Å–∞–º–æ–π –ø–æ—Å–ª–µ–¥–Ω–µ–π –∑–∞–ø–∏—Å–∏ URLContent –¥–ª—è –∫–∞–∂–¥–æ–≥–æ URL
        # url_content_qs = URLContent.objects.filter(url_id=OuterRef("id")).order_by("-created_at")[:1]
        #
        # # –û—Å–Ω–æ–≤–Ω–æ–π –∑–∞–ø—Ä–æ—Å —Å –∞–Ω–Ω–æ—Ç–∞—Ü–∏–µ–π –ø–æ–¥–∑–∞–ø—Ä–æ—Å–∞
        # urls = urls.select_related("report__storage", "site").annotate(
        #     urlcontent_total_count=Count("urlcontent"),
        #     # latest_urlcontent_body=Subquery(url_content_qs.values("body")[:1]),
        #     # latest_urlcontent_created_at=Subquery(url_content_qs.values("created_at")[:1])
        # )

        # –ü–æ–¥–∑–∞–ø—Ä–æ—Å –¥–ª—è –ø–æ—Å–ª–µ–¥–Ω–µ–π –∑–∞–ø–∏—Å–∏ URLContent –¥–ª—è –∫–∞–∂–¥–æ–≥–æ URL
        url_content_qs = URLContent.objects.filter(url_id=OuterRef("id")).order_by("-created_at")[:1]

        # –û—Å–Ω–æ–≤–Ω–æ–π –∑–∞–ø—Ä–æ—Å
        urls = urls.select_related("report__storage", "site").prefetch_related(
            Prefetch(
                "urlcontent_set",
                queryset=URLContent.objects.filter(id__in=Subquery(url_content_qs.values("id"))),
                to_attr="related_urlcontents"
            )
        ).annotate(
            urlcontent_total_count=Count("urlcontent")
        )

        # üìÑ –ü–∞–≥–∏–Ω–∞—Ü–∏—è
        paginator = Paginator(urls, 3)
        page_number = request_get.get("page")
        page_obj = paginator.get_page(page_number)

        # # üéØ –ù–∞–∑–Ω–∞—á–∞–µ–º active_urlcontent
        for url in page_obj.object_list:
            url.active_urlcontent = url.related_urlcontents[0] if url.related_urlcontents else None

        # üß© Query string –±–µ–∑ page
        query_params = request_get.copy()
        query_params.pop("page", None)
        paginator_query = query_params.urlencode()
        if paginator_query:
            paginator_query += "&"

        # üì¶ –ö–æ–Ω—Ç–µ–∫—Å—Ç
        context.update({
            "page_obj": page_obj,
            "paginator_query": paginator_query,
            "paginator": paginator,
            "urls": page_obj.object_list,
            "is_paginated": page_obj.has_other_pages(),
            "search_query": search_query,
            "status_filter": status_filter,
            "available_tags": available_tags,
            "tags_filter": tags_filter,
            "source_statuses": source_statuses,
            "filters": filters,
            "sorting_list": sorting_list,
            "standard_range_list": standard_range_list,
            "nonstandard_range_list": nonstandard_range_list,
        })

        return context


class WebSiteCreateView(LoginRequiredMixin, StoragePermissionMixin, CreateView):
    """–°–æ–∑–¥–∞–Ω–∏–µ –æ–±—ä–µ–∫—Ç–∞ –º–æ–¥–µ–ª–∏ –í–µ–±—Å–∞–π—Ç"""
    model = WebSite
    fields = ['name', 'base_url', 'xml_map_url']

    def dispatch(self, request, *args, **kwargs):
        """–°–æ—Ö—Ä–∞–Ω—è–µ–º knowledge_base –¥–ª—è –¥–∞–ª—å–Ω–µ–π—à–µ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è"""
        self.knowledge_base = get_object_or_404(KnowledgeBase, pk=kwargs['kb_pk'])
        return super().dispatch(request, *args, **kwargs)

    def form_valid(self, form):
        """–£—Å—Ç–∞–Ω–æ–≤–∫–∞ —Å–≤—è–∑–∏ —Å –±–∞–∑–æ–π –∑–Ω–∞–Ω–∏–π –ø–µ—Ä–µ–¥ –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π"""
        kb_pk = self.kwargs.get("kb_pk")
        if not kb_pk:
            form.add_error(None, "–ù–µ –ø–µ—Ä–µ–¥–∞–Ω ID –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π")
            return self.form_invalid(form)

        form.instance.kb = self.knowledge_base
        form.instance.author = self.request.user
        return super().form_valid(form)

    def get_form(self, form_class=None):
        form = super().get_form(form_class)

        kb_pk = self.kwargs.get("kb_pk")
        if kb_pk:
            form.instance.kb_id = kb_pk
        form.instance.author = self.request.user
        return form


class WebSiteUpdateView(LoginRequiredMixin, StoragePermissionMixin, UpdateView):
    """–†–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –æ–±—ä–µ–∫—Ç–∞ –º–æ–¥–µ–ª–∏ –í–µ–±—Å–∞–π—Ç"""
    model = WebSite
    fields = ['name', 'xml_map_url']


class WebSiteDeleteView(LoginRequiredMixin, DeleteView):
    """–£–¥–∞–ª–µ–Ω–∏–µ –æ–±—ä–µ–∫—Ç–∞ –º–æ–¥–µ–ª–∏ –í–µ–±—Å–∞–π—Ç"""
    model = WebSite

    def get_success_url(self):
        return self.object.kb.get_absolute_url()


class WebSiteTestParseView(LoginRequiredMixin, StoragePermissionMixin, View):
    """–¢–µ—Å—Ç–æ–≤—ã–π –ø–∞—Ä—Å–∏–Ω–≥ –æ–¥–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã —Å –∑–∞–ø–∏—Å—å—é –æ—Ç—á–µ—Ç–∞"""

    def get(self, request, pk, *args, **kwargs):
        website = get_object_or_404(WebSite, pk=pk)
        parser_dispatcher = WebParserDispatcher()
        all_parsers = parser_dispatcher.discover_parsers()

        test_url = request.GET.get("url")
        if not test_url:
            test_url = website.base_url
        parse_form_initial = {"url": test_url}

        try:
            website_test_parser = TestParser.objects.get(site=website, author=request.user)
        except TestParser.DoesNotExist:
            website_test_parser = None

        parser_config_form = None
        if website_test_parser:
            parse_form_initial["parser"] = website_test_parser.class_name
            try:
                parser_cls = parser_dispatcher.get_by_class_name(website_test_parser.class_name)
                parser_config_schema = getattr(parser_cls, "config_schema", {})
                parser_config_form = ParserDynamicConfigForm(
                    schema=parser_config_schema,
                    initial_config=website_test_parser.config
                )
            except ValueError:

                logger.error(
                    f"–î–ª—è WebSite {website.name} –Ω–µ –Ω–∞–π–¥–µ–Ω BaseWebParser –ø–æ "
                    f"class_name = {website_test_parser.class_name}"
                )
        parse_form = TestParseForm(parsers=all_parsers, initial=parse_form_initial)

        return render(request, "app_sources/website_test_parse_form.html", {
            "form": parse_form,
            "config_form": parser_config_form,
            "parser": website_test_parser,
            "website": website,
        })

    def post(self, request, pk):
        website = get_object_or_404(WebSite, id=pk)

        parser_dispatcher = WebParserDispatcher()
        all_parsers = parser_dispatcher.discover_parsers()
        parse_form = TestParseForm(request.POST, parsers=all_parsers)

        if not parse_form.is_valid():
            return render(request, "app_sources/website_test_parse_form.html", {
                "form": parse_form,
                "config_form": None,
                "website": website
            })

        clean_emoji = parse_form.cleaned_data["clean_emoji"]
        clean_text = parse_form.cleaned_data["clean_text"]

        parser_cls = parse_form.cleaned_data["parser"]
        parser_config_schema = getattr(parser_cls, "config_schema", {})
        parser_config_form = ParserDynamicConfigForm(request.POST, schema=parser_config_schema)

        if not parser_config_form.is_valid():
            return render(request, "app_sources/website_test_parse_form.html", {
                "form": parse_form,
                "config_form": parser_config_form,
                "website": website
            })

        parser_config = parser_config_form.cleaned_data

        url = parse_form.cleaned_data["url"]
        test_parser, created = TestParser.create_or_update(
            site=website,
            author=request.user,
            class_name=f"{parser_cls.__module__}.{parser_cls.__name__}",
            config=parser_config,

        )
        test_parser_report, created = TestParseReport.objects.get_or_create(
            parser=test_parser,
            defaults={
                "url": url,
                "author": request.user,
            }
        )
        if not created:
            test_parser_report.url = url
            test_parser_report.status = None
            test_parser_report.html = ""
            test_parser_report.parsed_data = {}
            test_parser_report.error = ""
            test_parser_report.author = request.user
            test_parser_report.save()

        task = test_single_url.delay(
            url=url,
            parser=test_parser,
            author_id=request.user.pk,
            webdriver_options=None,  # –µ—Å–ª–∏ –Ω–µ –∑–∞–¥–∞—Ç—å, —Ç–æ –ø—Ä–∏–º–µ–Ω—è—Ç—Å—è –¥–µ—Ñ–æ–ª—Ç–Ω—ã–µ –≤ –∫–ª–∞—Å—Å–µ
            clean_text=clean_text,
            clean_emoji=clean_emoji,
        )

        # test_single_url(
        #     url=url,
        #     parser=test_parser,
        #     author_id=request.user.pk,
        #     webdriver_options=None,  # –µ—Å–ª–∏ –Ω–µ –∑–∞–¥–∞—Ç—å, —Ç–æ –ø—Ä–∏–º–µ–Ω—è—Ç—Å—è –¥–µ—Ñ–æ–ª—Ç–Ω—ã–µ –≤ –∫–ª–∞—Å—Å–µ
        #     clean_text=clean_text,
        #     clean_emoji=clean_emoji,
        # )
        #
        # return redirect(reverse_lazy("parsers:testparser_detail", kwargs={"pk": test_parser.pk}))

        return render(request, "celery_task_progress.html", {
            "task_id": task.id,
            "task_name": f"–¢–µ—Å—Ç–æ–≤—ã–π –ø–∞—Ä—Å–∏–Ω–≥ —Å—Ç—Ä–∞–Ω–∏—Ü—ã {url}",
            "task_object_url": reverse_lazy("sources:website_detail", kwargs={"pk": website.pk}),
            "task_object_name": website.name,
            "next_step_url": reverse_lazy("parsers:testparser_detail", kwargs={"pk": test_parser.pk}),
        })


class WebSiteBulkParseView(LoginRequiredMixin, StoragePermissionMixin, View):
    """–ü–∞—Ä—Å–∏–Ω–≥ —Å–ø–∏—Å–∫–∞ —Å—Å—ã–ª–æ–∫"""

    def get(self, request, pk, *args, **kwargs):
        website = get_object_or_404(WebSite, pk=pk)
        current_parser = None

        parse_form_initial = {"urls": website.base_url}
        website_main_parser = getattr(website, "mainparser", None)
        if website_main_parser:
            current_parser = website_main_parser
            parse_form = BulkParseForm(initial=parse_form_initial)
            try:
                parser_cls = WebParserDispatcher().get_by_class_name(website_main_parser.class_name)
            except ValueError:

                logger.error(
                    f"–î–ª—è WebSite {website.name} –Ω–µ –Ω–∞–π–¥–µ–Ω BaseWebParser –ø–æ "
                    f"class_name = {website_main_parser.class_name}"
                )
        else:
            parse_form = None

        return render(request, "app_sources/website_mass_parse_form.html", {
            "form": parse_form,
            "parser": current_parser,
            "website": website,
        })

    def post(self, request, pk):
        website = get_object_or_404(WebSite, id=pk)
        website_main_parser = getattr(website, "mainparser", None)
        if not website_main_parser:
            pass
        parse_form = BulkParseForm(request.POST)

        if not parse_form.is_valid():
            return render(request, "app_sources/website_mass_parse_form.html", {
                "form": parse_form,
                "parser": website_main_parser,
                "website": website,
            })

        clean_emoji = parse_form.cleaned_data["clean_emoji"]
        clean_text = parse_form.cleaned_data["clean_text"]
        urls = parse_form.cleaned_data["urls"]

        parser_config = website.mainparser.config

        main_parser, created = MainParser.objects.update_or_create(
            site=website,
            defaults={
                # "class_name": f"{parser_cls.__module__}.{parser_cls.__name__}",
                "config": parser_config,
                "author": request.user,
            }
        )

        website_update_report = WebSiteUpdateReport.objects.create(
            storage=website,
            author=request.user,
            content={
                "urls": urls,
                "parser_class": main_parser.class_name,
                "parser_config": main_parser.config,
            }
        )

        task = parse_urls_task.delay(
            parser=main_parser,
            urls=urls,
            website_update_report_pk=website_update_report.pk,
            webdriver_options=None,  # –µ—Å–ª–∏ –Ω–µ –∑–∞–¥–∞—Ç—å, —Ç–æ –ø—Ä–∏–º–µ–Ω—è—Ç—Å—è –¥–µ—Ñ–æ–ª—Ç–Ω—ã–µ –≤ –∫–ª–∞—Å—Å–µ
            clean_text=clean_text,
            clean_emoji=clean_emoji,
        )

        return render(request, "celery_task_progress.html", {
            "task_id": task.id,
            "task_name": f"–ú–∞—Å—Å–æ–≤—ã–π –ø–∞—Ä—Å–∏–Ω–≥ —Å—Ç—Ä–∞–Ω–∏—Ü —Å–∞–π—Ç–∞ {website.name}",
            "task_object_url": reverse_lazy("sources:website_detail", kwargs={"pk": website.pk}),
            "task_object_name": website.name,
            "next_step_url": reverse_lazy("sources:websiteupdatereport_detail",
                                          kwargs={"pk": website_update_report.pk}),
        })


class WebSiteSynchronizationView(LoginRequiredMixin, StoragePermissionMixin, View):

    def get(self, request, pk, *args, **kwargs):
        website = get_object_or_404(WebSite, pk=pk)
        current_parser = None

        website_main_parser = getattr(website, "mainparser", None)
        if website_main_parser:
            current_parser = website_main_parser

        return render(request, "app_sources/website_parse_form.html", {
            "parser": current_parser,
            "website": website,
        })

    def post(self, request, pk):
        website = get_object_or_404(WebSite, id=pk)
        mode = request.GET.get("mode", "test")

        if mode == "bulk":
            parse_form = BulkParseForm(request.POST)
        else:
            parser_dispatcher = WebParserDispatcher()
            all_parsers = parser_dispatcher.discover_parsers()
            parse_form = TestParseForm(request.POST, parsers=all_parsers)

        if not parse_form.is_valid():
            return render(request, "app_sources/website_parse_form.html", {
                "form": parse_form,
                "config_form": None,
                "mode": mode,
                "website": website
            })

        clean_emoji = parse_form.cleaned_data["clean_emoji"]
        clean_text = parse_form.cleaned_data["clean_text"]

        if mode == "bulk":
            parser_config = website.mainparser.config

        else:
            parser_cls = parse_form.cleaned_data["parser"]
            parser_config_schema = getattr(parser_cls, "config_schema", {})
            parser_config_form = ParserDynamicConfigForm(request.POST, schema=parser_config_schema)

            if not parser_config_form.is_valid():
                return render(request, "app_sources/website_parse_form.html", {
                    "form": parse_form,
                    "config_form": parser_config_form,
                    "mode": mode,
                    "website": website
                })

            parser_config = parser_config_form.cleaned_data

        if mode == "bulk":
            urls = parse_form.cleaned_data["urls"]
            main_parser, created = MainParser.objects.update_or_create(
                site=website,
                defaults={
                    # "class_name": f"{parser_cls.__module__}.{parser_cls.__name__}",
                    "config": parser_config,
                    "author": request.user,
                }
            )

            website_update_report = WebSiteUpdateReport.objects.create(
                storage=website,
                author=request.user,
                content={
                    "urls": urls,
                    "mode": mode,
                    "parser_class": main_parser.class_name,
                    "parser_config": main_parser.config,
                }
            )

            task = parse_urls_task.delay(
                urls=urls,
                parser=main_parser,
                author_id=request.user.pk,
                website_update_report_pk=website_update_report.pk,
                webdriver_options=None,  # –µ—Å–ª–∏ –Ω–µ –∑–∞–¥–∞—Ç—å, —Ç–æ –ø—Ä–∏–º–µ–Ω—è—Ç—Å—è –¥–µ—Ñ–æ–ª—Ç–Ω—ã–µ –≤ –∫–ª–∞—Å—Å–µ
                clean_text=clean_text,
                clean_emoji=clean_emoji,
            )

            return render(request, "celery_task_progress.html", {
                "task_id": task.id,
                "task_name": f"–ú–∞—Å—Å–æ–≤—ã–π –ø–∞—Ä—Å–∏–Ω–≥ —Å—Ç—Ä–∞–Ω–∏—Ü —Å–∞–π—Ç–∞ {website.name}",
                "task_object_url": reverse_lazy("sources:website_detail", kwargs={"pk": website.pk}),
                "task_object_name": website.name,
                "next_step_url": reverse_lazy("sources:websiteupdatereport_detail",
                                              kwargs={"pk": website_update_report.pk}),
            })

        else:
            url = parse_form.cleaned_data["url"]
            test_parser, created = TestParser.create_or_update(
                site=website,
                author=request.user,
                class_name=f"{parser_cls.__module__}.{parser_cls.__name__}",
                config=parser_config,

            )
            test_parser_report, created = TestParseReport.objects.get_or_create(
                parser=test_parser,
                defaults={
                    "url": url,
                    "author": request.user,
                }
            )
            if not created:
                test_parser_report.url = url
                test_parser_report.status = None
                test_parser_report.html = ""
                test_parser_report.parsed_data = {}
                test_parser_report.error = ""
                test_parser_report.author = request.user
                test_parser_report.save()

            task = test_single_url.delay(
                url=url,
                parser=test_parser,
                author_id=request.user.pk,
                webdriver_options=None,  # –µ—Å–ª–∏ –Ω–µ –∑–∞–¥–∞—Ç—å, —Ç–æ –ø—Ä–∏–º–µ–Ω—è—Ç—Å—è –¥–µ—Ñ–æ–ª—Ç–Ω—ã–µ –≤ –∫–ª–∞—Å—Å–µ
                clean_text=clean_text,
                clean_emoji=clean_emoji,
            )

            # test_single_url(
            #     url=url,
            #     parser=test_parser,
            #     author_id=request.user.pk,
            #     webdriver_options=None,  # –µ—Å–ª–∏ –Ω–µ –∑–∞–¥–∞—Ç—å, —Ç–æ –ø—Ä–∏–º–µ–Ω—è—Ç—Å—è –¥–µ—Ñ–æ–ª—Ç–Ω—ã–µ –≤ –∫–ª–∞—Å—Å–µ
            #     clean_text=clean_text,
            #     clean_emoji=clean_emoji,
            # )
            #
            # return redirect(reverse_lazy("parsers:testparser_detail", kwargs={"pk": test_parser.pk}))

            return render(request, "celery_task_progress.html", {
                "task_id": task.id,
                "task_name": f"–¢–µ—Å—Ç–æ–≤—ã–π –ø–∞—Ä—Å–∏–Ω–≥ —Å—Ç—Ä–∞–Ω–∏—Ü—ã {url}",
                "task_object_url": reverse_lazy("sources:website_detail", kwargs={"pk": website.pk}),
                "task_object_name": website.name,
                "next_step_url": reverse_lazy("parsers:testparser_detail", kwargs={"pk": test_parser.pk}),
            })


class WebSiteTestParseReportView(LoginRequiredMixin, View):
    """–ö–ª–∞—Å—Å –æ—Ç—á–µ—Ç–∞ –ø–æ —Ç–µ—Å—Ç–æ–≤–æ–º—É –ø–∞—Ä—Å–∏–Ω–≥—É —Å—Ç—Ä–∞–Ω–∏—Ü—ã —Å–∞–π—Ç–∞"""

    def get(self, request, pk):
        website = get_object_or_404(WebSite, id=pk)
        test_report = get_object_or_404(TestParseReport, site=website, author=request.user)
        context = {
            "website": website,
            "report": test_report,
        }
        return render(request, "app_sources/testparseresult_detail.html", context)


class URLBatchDetailView(LoginRequiredMixin, StoragePermissionMixin, DetailView):
    """–î–µ—Ç–∞–ª—å–Ω—ã–π –ø—Ä–æ—Å–º–æ—Ç—Ä –æ–±—ä–µ–∫—Ç–∞ –º–æ–¥–µ–ª–∏ –í–µ–±-–∫–æ–ª–ª–µ–∫—Ü–∏—è URLBatch(—Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π –ø—Ä–∞–≤ –¥–æ—Å—Ç—É–ø–∞)"""
    model = URLBatch

    def get(self, *args, **kwargs):
        return HttpResponse("–ó–∞–≥–ª—É—à–∫–∞")


class URLBatchCreateView(LoginRequiredMixin, StoragePermissionMixin, CreateView):
    """–°–æ–∑–¥–∞–Ω–∏–µ –æ–±—ä–µ–∫—Ç–∞ –º–æ–¥–µ–ª–∏ –í–µ–±-–∫–æ–ª–ª–µ–∫—Ü–∏—è URLBatch"""
    model = URLBatch

    def get(self, *args, **kwargs):
        return HttpResponse("–ó–∞–≥–ª—É—à–∫–∞")


class URLBatchUpdateView(LoginRequiredMixin, StoragePermissionMixin, UpdateView):
    """–†–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –æ–±—ä–µ–∫—Ç–∞ –º–æ–¥–µ–ª–∏ –í–µ–±-–∫–æ–ª–ª–µ–∫—Ü–∏—è URLBatch"""
    model = URLBatch

    def get(self, *args, **kwargs):
        return HttpResponse("–ó–∞–≥–ª—É—à–∫–∞")


class URLBatchDeleteView(LoginRequiredMixin, DeleteView):
    """–£–¥–∞–ª–µ–Ω–∏–µ –æ–±—ä–µ–∫—Ç–∞ –º–æ–¥–µ–ª–∏ –í–µ–±-–∫–æ–ª–ª–µ–∫—Ü–∏—è URLBatch"""
    model = URLBatch

    def get(self, *args, **kwargs):
        return HttpResponse("–ó–∞–≥–ª—É—à–∫–∞")


class URLDetailView(LoginRequiredMixin, DocumentPermissionMixin, DetailView):
    """–î–µ—Ç–∞–ª—å–Ω—ã–π –ø—Ä–æ—Å–º–æ—Ç—Ä –æ–±—ä–µ–∫—Ç–∞ –º–æ–¥–µ–ª–∏ –ú–æ–¥–µ–ª—å —Å—Ç—Ä–∞–Ω–∏—Ü—ã —Å–∞–π—Ç–∞ URL (—Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π –ø—Ä–∞–≤ –¥–æ—Å—Ç—É–ø–∞)"""
    model = URL
    urlcontent_preview_set = Prefetch(
        "urlcontent_set",
        queryset=URLContent.objects
            .select_related("report", "author")
            .annotate(
                body_length=Length("body"),
                body_preview=Left("body", 200)
            ).defer("body"),
        to_attr="urlcontent_preview_set"
    )
    queryset = (URL.objects.select_related("site", "site__kb", "report",)
                .prefetch_related(urlcontent_preview_set, "tasks"))


class URLUpdateView(LoginRequiredMixin, DocumentPermissionMixin, DetailView):
    """–†–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –æ–±—ä–µ–∫—Ç–∞ –º–æ–¥–µ–ª–∏ –ú–æ–¥–µ–ª—å —Å—Ç—Ä–∞–Ω–∏—Ü—ã —Å–∞–π—Ç–∞ URL (—Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π –ø—Ä–∞–≤ –¥–æ—Å—Ç—É–ø–∞)"""
    model = URL

    def get(self,*args, **kwargs):
        return HttpResponse("–ó–∞–≥–ª—É—à–∫–∞")


class RawContentRecognizeCreateView(LoginRequiredMixin, View):
    def get(self, request, pk, *args, **kwargs):
        raw_content = get_object_or_404(RawContent, pk=pk)
        document = raw_content.network_document
        storage = document.storage
        kb = storage.kb
        context = {
            "content": raw_content,
            "document": document,
            "storage": storage,
            "kb": kb,
        }
        # —Ñ–æ—Ä–º–∞ –≤—ã–±–æ—Ä–∞ –∫–ª–∞—Å—Å–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞—Ç–µ–ª—è
        dispatcher = ContentRecognizerDispatcher()
        file_extension = raw_content.file_extension()
        recognizers = dispatcher.get_recognizers_for_extension(file_extension)
        form = ContentRecognizerForm(recognizers=recognizers)
        context["form"] = form
        return render(request, "app_sources/rawcontent_recognize.html", context)


    def post(self, request, pk):
        raw_content = get_object_or_404(RawContent, pk=pk)
        dispatcher = ContentRecognizerDispatcher()
        file_extension = raw_content.file_extension()
        recognizers = dispatcher.get_recognizers_for_extension(file_extension)

        form = ContentRecognizerForm(request.POST, recognizers=recognizers)

        if form.is_valid():
            recognizer_class = form.cleaned_data['recognizer']
            file_path = raw_content.file.path
            # print(recognizer_name)
            # recognizer = dispatcher.get_by_name(recognizer_name)
            try:
                recognizer = recognizer_class(file_path)
                recognizer_report = recognizer.recognize()
                recognized_text = recognizer_report.get("text", "")
                recognition_method = recognizer_report.get("method", "")
                recognition_quality_report = recognizer_report.get("quality_report", {})
                if not recognized_text.strip():
                    raise ValueError("–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å —Ç–µ–∫—Å—Ç.")
                # –£–Ω–∏—á—Ç–æ–∂–µ–Ω–∏–µ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ CleanedContent
                CleanedContent.objects.filter(raw_content=raw_content).delete()

                # –°–æ–∑–¥–∞—ë–º CleanedContent –±–µ–∑ —Ñ–∞–π–ª–∞
                cleaned_content = CleanedContent.objects.create(
                    raw_content=raw_content,
                    recognition_method=recognition_method,
                    recognition_quality=recognition_quality_report,
                    preview=recognized_text[:200] if recognized_text else None,
                    author=request.user,
                )
                raw_content_source = next(
                    ((attr, getattr(raw_content, attr)) for attr in ['url', 'network_document', 'local_document'] if
                     getattr(raw_content, attr, None)),
                    (None, None)
                )
                source_name, source_value = raw_content_source
                setattr(cleaned_content, source_name, source_value)
                cleaned_content.save()
                cleaned_content.file.save("ignored.txt", ContentFile(recognized_text.encode('utf-8')))

                messages.success(request, "–û—á–∏—â–µ–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç —É—Å–ø–µ—à–Ω–æ —Å–æ–∑–¥–∞–Ω.")
                return redirect("sources:cleanedcontent_detail", pk=cleaned_content.pk)
            except Exception as e:
                messages.error(request, f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ñ–∞–π–ª–∞: {e}")
        print(form.errors)
        document = raw_content.network_document
        storage = document.storage
        kb = storage.kb
        context = {
            "content": raw_content,
            "document": document,
            "storage": storage,
            "kb": kb,
            "form": form,
        }
        return render(request, "app_sources/rawcontent_recognize.html", context)


class RawContentDetailView(LoginRequiredMixin, DetailView):
    model = RawContent


class CleanedContentDetailView(LoginRequiredMixin, DetailView):
    model = CleanedContent

    def get_context_data(self, **kwargs):
        context = super().get_context_data(**kwargs)
        if self.object.file:
            try:
                with self.object.file.open('rb') as f:  # –û—Ç–∫—Ä—ã–≤–∞–µ–º –≤ –±–∏–Ω–∞—Ä–Ω–æ–º —Ä–µ–∂–∏–º–µ
                    raw_content = f.read()  # –ß–∏—Ç–∞–µ–º –∫–∞–∫ –±–∞–π—Ç—ã
                    content = raw_content.decode('utf-8')  # –î–µ–∫–æ–¥–∏—Ä—É–µ–º –≤ —Å—Ç—Ä–æ–∫—É
                    context['file_content'] = content
            except UnicodeDecodeError:
                context['file_content'] = "–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–∞: –Ω–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º–∞—è –∫–æ–¥–∏—Ä–æ–≤–∫–∞."

            except Exception as e:
                context['file_content'] = f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞: {e}"
        return context


class CleanedContentUpdateView(LoginRequiredMixin, View):
    def get(self, request, pk):
        cleaned_content = CleanedContent.objects.get(pk=pk)
        editor_content = ""
        if cleaned_content.file:
            try:
                with cleaned_content.file.open('rb') as f:  # –û—Ç–∫—Ä—ã–≤–∞–µ–º –≤ –±–∏–Ω–∞—Ä–Ω–æ–º —Ä–µ–∂–∏–º–µ
                    raw_content = f.read()  # –ß–∏—Ç–∞–µ–º –∫–∞–∫ –±–∞–π—Ç—ã
                    editor_content = raw_content.decode('utf-8')  # –î–µ–∫–æ–¥–∏—Ä—É–µ–º –≤ —Å—Ç—Ä–æ–∫—É
            except UnicodeDecodeError:
                raise Http404("–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–∞: –Ω–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º–∞—è –∫–æ–¥–∏—Ä–æ–≤–∫–∞.")
            except Exception as e:
                Http404(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞ {str(e)}")

        form = CleanedContentEditorForm(initial={"content": editor_content})
        context = {
            "form": form,
        }
        return render(request=request, template_name="app_sources/cleanedcontent_form.html", context=context)

    def post(self, request, pk):
        cleaned_content = CleanedContent.objects.get(pk=pk)
        form = CleanedContentEditorForm(request.POST)
        if form.is_valid():
            content = form.cleaned_data.get("content")
            print(content[:200])
            cleaned_content.preview = content[:200] if content else None
            cleaned_content.save(update_fields=["preview", ])
            cleaned_content.file.save("ignored.txt", ContentFile(content.encode('utf-8')))
            return redirect(reverse_lazy("sources:cleanedcontent_detail", args=[cleaned_content.pk]))
        context = {
            "form": form,
        }
        return render(request=request, template_name="app_sources/cleanedcontent_form.html", context=context)


class URLContentDetailView(LoginRequiredMixin, DetailView):
    """–î–µ—Ç–∞–ª—å–Ω—ã–π –ø—Ä–æ—Å–º–æ—Ç—Ä –æ–±—ä–µ–∫—Ç–∞ URLContent"""
    model = URLContent
    queryset = URLContent.objects.select_related()

    def get_context_data(self, **kwargs):
        context = super().get_context_data(**kwargs)
        url_content = self.object
        url = url_content.url
        site = url.site
        kb = site.kb
        context.update({
            "content": url_content,
            "document": url,
            "document_type_ru": "–≤–µ–±-—Å—Ç—Ä–∞–Ω–∏—Ü–∞",
            "storage_type_eng": "website",
            "storage": site,
            "storage_type_ru": "–≤–µ–±-—Å–∞–π—Ç",
            "kb": kb,
        })
        return context


class URLContentUpdateView(LoginRequiredMixin, View):
    def get(self, request, pk):
        url_content = URLContent.objects.get(pk=pk)
        editor_content = url_content.body

        form = CleanedContentEditorForm(initial={"content": editor_content})
        context = {
            "form": form,
            "content": url_content,
        }
        return render(request=request, template_name="app_sources/cleanedcontent_form.html", context=context)

    def post(self, request, pk):
        url_content = URLContent.objects.get(pk=pk)
        form = CleanedContentEditorForm(request.POST)
        if form.is_valid():
            content = form.cleaned_data.get("content")
            print(content)
            url_content.body = content
            url_content.save()
            return redirect(reverse_lazy("sources:urlcontent_detail", args=[url_content.pk]))
        context = {
            "form": form,
            "content": url_content,
        }
        return render(request=request, template_name="app_sources/cleanedcontent_form.html", context=context)