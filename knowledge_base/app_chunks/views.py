import json
import os
import pickle
import re
import tempfile
from collections import Counter
from datetime import datetime

import tiktoken
from django.contrib.auth.mixins import LoginRequiredMixin
from django.db import NotSupportedError
from django.http import HttpResponse, JsonResponse, HttpResponseBadRequest
from django.template.loader import render_to_string
from django.utils.safestring import mark_safe
from django.utils.timezone import make_aware
from django.views import View
from django.db.models import Subquery, OuterRef, Q, Prefetch, Count, ExpressionWrapper, F, IntegerField
from django.db.models.functions import Length
from django.http import StreamingHttpResponse
from django.shortcuts import render, redirect, get_object_or_404
from django.urls import reverse_lazy
from django.views.generic import ListView, DetailView

from langchain_core.documents import Document
from langchain_text_splitters import MarkdownHeaderTextSplitter, RecursiveCharacterTextSplitter

from app_chunks.forms import SplitterSelectForm, SplitterDynamicConfigForm
from app_chunks.models import Chunk, ChunkStatus, ChunkingReport
from app_chunks.splitters.dispatcher import SplitterDispatcher
from app_chunks.tasks import bulk_chunks_create, universal_bulk_chunks_create
from app_sources.content_models import URLContent, RawContent, ContentStatus, CleanedContent
from app_sources.source_models import SourceStatus
from app_sources.storage_models import WebSite, CloudStorage, LocalStorage, URLBatch
from utils.setup_logger import setup_logger

logger = setup_logger(__name__, log_dir="logs/chunking", log_file="chunking.log")


class SplitterConfigView(LoginRequiredMixin, View):
    """–í—å—é –ø–æ–ª—É—á–µ–Ω–∏—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ —Å–ø–ª–∏—Ç—Ç–µ—Ä–∞ –ø–æ –∫–ª–∞—Å—Å—É"""

    def get(self, request, *args, **kwargs):
        splitter_class_name = request.GET.get("splitter_class_name")
        if not splitter_class_name:
            return HttpResponseBadRequest("–ü–∞—Ä–∞–º–µ—Ç—Ä 'splitter_class_name' –æ–±—è–∑–∞—Ç–µ–ª–µ–Ω")

        try:
            dispatcher = SplitterDispatcher()
            splitter_cls = dispatcher.get_by_name(splitter_class_name)
        except ValueError:
            return HttpResponseBadRequest("–°–ø–ª–∏—Ç—Ç–µ—Ä –Ω–µ –Ω–∞–π–¥–µ–Ω")

        config_schema = getattr(splitter_cls, "config_schema", {})
        config_form = SplitterDynamicConfigForm(schema=config_schema)
        form_html = render_to_string("widgets/_form_content-widget.html", {
            "form": config_form,
        }, request=request)

        splitter_help = getattr(splitter_cls, "help_text", "")
        help_html = mark_safe(f'<div class="_mb"><p class="text text--accent text--bold">{splitter_help}</p></div>')
        html = help_html + form_html

        return HttpResponse(html)


def split_markdown_text(markdown_text,
                        strip_headers=False):  # –ù–ï —É–¥–∞–ª—è—Ç—å –∑–∞–≥–æ–ª–æ–≤–∫–∏ –ø–æ–¥ '#..' –∏–∑ page_content

    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∑–∞–≥–æ–ª–æ–≤–∫–∏, –ø–æ –∫–æ—Ç–æ—Ä—ã–º –±—É–¥–µ–º —Ä–∞–∑–±–∏–≤–∞—Ç—å —Ç–µ–∫—Å—Ç
    headers_to_split_on = [("#", "Header 1"),  # –ó–∞–≥–æ–ª–æ–≤–æ–∫ –ø–µ—Ä–≤–æ–≥–æ —É—Ä–æ–≤–Ω—è
                           ("##", "Header 2"),  # –ó–∞–≥–æ–ª–æ–≤–æ–∫ –≤—Ç–æ—Ä–æ–≥–æ —É—Ä–æ–≤–Ω—è
                           ("###", "Header 3")]  # –ó–∞–≥–æ–ª–æ–≤–æ–∫ —Ç—Ä–µ—Ç—å–µ–≥–æ —É—Ä–æ–≤–Ω—è
    # –°–æ–∑–¥–∞–µ–º —ç–∫–∑–µ–º–ø–ª—è—Ä MarkdownHeaderTextSplitter —Å –∑–∞–¥–∞–Ω–Ω—ã–º–∏ –∑–∞–≥–æ–ª–æ–≤–∫–∞–º–∏
    markdown_splitter = MarkdownHeaderTextSplitter(headers_to_split_on,
                                                   strip_headers=strip_headers)
    # –†–∞–∑–±–∏–≤–∞–µ–º —Ç–µ–∫—Å—Ç –Ω–∞ —á–∞–Ω–∫–∏ –≤ —Ñ–æ—Ä–º–∞—Ç LangChain Document
    chunks = markdown_splitter.split_text(markdown_text)
    return chunks  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Å–ø–∏—Å–æ–∫ —á–∞–Ω–∫–æ–≤ –≤ —Ñ–æ—Ä–º–∞—Ç–µ LangChain


def num_tokens_from_string(string: str, encoding_name: str) -> int:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤ –≤ —Å—Ç—Ä–æ–∫–µ"""
    encoding = tiktoken.get_encoding(encoding_name)
    num_tokens = len(encoding.encode(string))
    return num_tokens


def split_text(text, max_count):
    headers_to_split_on = [
        ("#", "Header 1"),
        # ("##", "Header 2"),
    ]

    markdown_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=headers_to_split_on, strip_headers=False)
    fragments = markdown_splitter.split_text(text)

    # –ü–æ–¥—Å—á–µ—Ç —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞ –∏ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–∞
    fragment_token_counts = [num_tokens_from_string(fragment.page_content, "cl100k_base") for fragment in fragments]
    # plt.hist(fragment_token_counts, bins=50, alpha=0.5, label='Fragments')
    # plt.title('Distribution of Fragment Token Counts')
    # plt.xlabel('Token Count')
    # plt.ylabel('Frequency')
    # plt.show()
    # print(fragment_token_counts)
    # for fragment in fragments:
    #     if num_tokens_from_string(fragment.page_content, "cl100k_base") > max_count:
    #         print(fragment)

    splitter = RecursiveCharacterTextSplitter(
        chunk_size=max_count,
        chunk_overlap=50,
        length_function=lambda x: num_tokens_from_string(x, "cl100k_base")
    )

    source_chunks = [
        Document(page_content=chunk, metadata=fragment.metadata)
        for fragment in fragments
        for chunk in splitter.split_text(fragment.page_content)
    ]

    # –ü–æ–¥—Å—á–µ—Ç —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ source_chunk –∏ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–∞
    source_chunk_token_counts = [num_tokens_from_string(chunk.page_content, "cl100k_base") for chunk in source_chunks]
    # plt.hist(source_chunk_token_counts, bins=20, alpha=0.5, label='Source Chunks')
    # plt.title('Distribution of Source Chunk Token Counts')
    # plt.xlabel('Token Count')
    # plt.ylabel('Frequency')
    # plt.show()
    # print(source_chunk_token_counts)

    return source_chunks, fragments


def deep_clean_metadata(obj):
    if isinstance(obj, dict):
        return {k: deep_clean_metadata(v) for k, v in obj.items() if deep_clean_metadata(v)}
    elif isinstance(obj, list):
        return [deep_clean_metadata(v) for v in obj if deep_clean_metadata(v)]
    return obj if obj not in (None, "", [], {}) else None


def process_document(doc: Document) -> Document:
    # –ò–∑–≤–ª–µ–∫–∞–µ–º page_content –∏ metadata –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞
    page_content = doc.page_content
    metadata = doc.metadata.copy()  # –°–æ–∑–¥–∞—ë–º –∫–æ–ø–∏—é metadata
    files = metadata.get('files', {})

    # –†–µ–∫—É—Ä—Å–∏–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤–ª–æ–∂–µ–Ω–Ω—ã—Ö —Å–ª–æ–≤–∞—Ä–µ–π –∏ —Å–ø–∏—Å–∫–æ–≤ –≤ files
    def process_files(data, page_content, prefix='files', parent_name=None):
        if isinstance(data, dict):
            for key, value in data.items():
                page_content = process_files(value, page_content, f"{prefix}__{key}", parent_name)
        elif isinstance(data, list):
            for i, item in enumerate(data):
                # –ï—Å–ª–∏ —ç–ª–µ–º–µ–Ω—Ç —Å–ø–∏—Å–∫–∞ ‚Äî —Å–ø–∏—Å–æ–∫, –ø–µ—Ä–µ–¥–∞—ë–º –ø–µ—Ä–≤—ã–π —ç–ª–µ–º–µ–Ω—Ç –∫–∞–∫ –∏–º—è
                if isinstance(item, list):
                    name = item[0] if len(item) > 0 else None
                    for j, sub_item in enumerate(item):
                        page_content = process_files(sub_item, page_content, f"{prefix}__{i}__{j}", name)
                else:
                    page_content = process_files(item, page_content, f"{prefix}__{i}", parent_name)
        elif isinstance(data, str) and 'http' in data:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Å—Ç—Ä–æ–∫–∞ —Å—Å—ã–ª–∫–æ–π
            # –ò—â–µ–º —Å—Å—ã–ª–∫—É –≤ page_content –≤ —Ñ–æ—Ä–º–∞—Ç–µ Markdown –∏–ª–∏ –∫–∞–∫ —á–∏—Å—Ç—É—é —Å—Ç—Ä–æ–∫—É
            markdown_pattern = rf'!\[(.*?)\]\({re.escape(data)}\)'
            match = re.search(markdown_pattern, page_content)
            if match or data in page_content:
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º parent_name –∫–∞–∫ –Ω–∞–∑–≤–∞–Ω–∏–µ, –µ—Å–ª–∏ –æ–Ω–æ –µ—Å—Ç—å, –∏–Ω–∞—á–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –∏–∑ Markdown –∏–ª–∏ —Å—Å—ã–ª–∫—É
                name = parent_name if parent_name else (match.group(1) if match else data)
                # –î–æ–±–∞–≤–ª—è–µ–º –≤ metadata –Ω–∞ –∫–æ—Ä–Ω–µ–≤–æ–π —É—Ä–æ–≤–µ–Ω—å
                metadata[prefix] = f"{name} {data}"
                # –ó–∞–º–µ–Ω—è–µ–º Markdown-—Å—Å—ã–ª–∫—É –Ω–∞ –Ω–∞–∑–≤–∞–Ω–∏–µ –∏–ª–∏ —á–∏—Å—Ç—É—é —Å—Å—ã–ª–∫—É –Ω–∞ –∏–º—è
                if match:
                    page_content = re.sub(markdown_pattern, match.group(1), page_content)
                else:
                    page_content = page_content.replace(data, name)
        return page_content

    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –≤—Å–µ —ç–ª–µ–º–µ–Ω—Ç—ã –≤ files, –æ–±–Ω–æ–≤–ª—è—è page_content
    page_content = process_files(files, page_content)

    # –£–¥–∞–ª—è–µ—Ç Markdown-–∑–∞–≥–æ–ª–æ–≤–∫–∏ (###, ##, #) –≤ –ª—é–±–æ–º –º–µ—Å—Ç–µ —Å—Ç—Ä–æ–∫–∏
    page_content = re.sub(r'\s*#{1,6}\s*', ' ', page_content)
    # –£–¥–∞–ª—è–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã, –æ—Å—Ç–∞–≤—à–∏–µ—Å—è –ø–æ—Å–ª–µ –∑–∞–º–µ–Ω—ã Markdown-—Å—Å—ã–ª–æ–∫
    page_content = re.sub(r'\s+', ' ', page_content).strip()

    # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º files –≤ –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫
    metadata['files'] = []
    metadata = deep_clean_metadata(metadata)

    # –°–æ–∑–¥–∞—ë–º –Ω–æ–≤—ã–π –æ–±—ä–µ–∫—Ç Document —Å –æ–±–Ω–æ–≤–ª—ë–Ω–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
    return Document(page_content=page_content, metadata=metadata)


def flatten_metadata(d, parent_key='', sep='_'):
    """
    –†–µ–∫—É—Ä—Å–∏–≤–Ω–æ —Ä–∞–∑–≤–æ—Ä–∞—á–∏–≤–∞–µ—Ç –≤–ª–æ–∂–µ–Ω–Ω—ã–π —Å–ª–æ–≤–∞—Ä—å/—Å–ø–∏—Å–æ–∫ –≤ –ø–ª–æ—Å–∫–∏–π —Å–ª–æ–≤–∞—Ä—å.
    –ö–ª—é—á–∏ —Å–æ–µ–¥–∏–Ω—è—é—Ç—Å—è —á–µ—Ä–µ–∑ sep, —Å–ø–∏—Å–∫–∏ –∏–Ω–¥–µ–∫—Å–∏—Ä—É—é—Ç—Å—è.
    """
    items = []
    if isinstance(d, dict):
        for k, v in d.items():
            new_key = f"{parent_key}{sep}{k}" if parent_key else k
            items.extend(flatten_metadata(v, new_key, sep=sep).items())
    elif isinstance(d, list):
        for i, v in enumerate(d):
            new_key = f"{parent_key}{sep}{i}"
            items.extend(flatten_metadata(v, new_key, sep=sep).items())
    else:
        items.append((parent_key, d))
    return dict(items)


def save_documents_to_file(all_documents, filename):
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É, –≤ –∫–æ—Ç–æ—Ä–æ–º –±—É–¥—É—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –¥–æ–∫—É–º–µ–Ω—Ç—ã
    file_path = os.path.join(os.pardir, filename)

    # –û—Ç–∫—Ä—ã–≤–∞–µ–º —Ñ–∞–π–ª –¥–ª—è –∑–∞–ø–∏—Å–∏ –≤ –±–∏–Ω–∞—Ä–Ω–æ–º —Ä–µ–∂–∏–º–µ
    with open(file_path, 'wb') as f:
        # –°–µ—Ä–∏–∞–ª–∏–∑—É–µ–º (—Å–æ—Ö—Ä–∞–Ω—è–µ–º) —Å–ø–∏—Å–æ–∫ all_documents –≤ —Ñ–∞–π–ª
        pickle.dump(all_documents, f)
    print(f"–î–æ–∫—É–º–µ–Ω—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ —Ñ–∞–π–ª: {file_path}")


def save_documents_to_response(request, documents, is_ajax=False):
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç—ã –≤–æ –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –µ–≥–æ –≤ HTTP-–æ—Ç–≤–µ—Ç–µ —Å –ø–æ—Ç–æ–∫–æ–≤–æ–π –ø–µ—Ä–µ–¥–∞—á–µ–π."""
    if not documents:
        if is_ajax:
            return JsonResponse({"error": "No documents to save"}, status=400)
        return HttpResponse("No documents to save", status=400)

    temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.pickle',
                                            dir=os.path.dirname(os.path.abspath(__file__)))
    temp_file_path = temp_file.name

    try:
        # –°–µ—Ä–∏–∞–ª–∏–∑—É–µ–º –¥–æ–∫—É–º–µ–Ω—Ç—ã –∏ –∑–∞–∫—Ä—ã–≤–∞–µ–º —Ñ–∞–π–ª
        pickle.dump(documents, temp_file)
        temp_file.close()

        if is_ajax:
            # –î–ª—è AJAX: —á–∏—Ç–∞–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–∞ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–∞–∫ Blob —Å JSON
            file_content = temp_file.read()
            response = JsonResponse({
                "status": "success",
                "filename": "chunk.pickle",
                "content_type": "application/octet-stream"
            })
            response['Content-Disposition'] = 'attachment; filename="chunk.pickle"'
            response.content = file_content  # –ü–µ—Ä–µ–¥–∞—ë–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–∞
            return response

        def file_iterator(path):
            try:
                with open(path, 'rb') as f:
                    while chunk := f.read(8192):
                        yield chunk
            finally:
                # –£–¥–∞–ª—è–µ–º —Ñ–∞–π–ª –ø–æ—Å–ª–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –ø–µ—Ä–µ–¥–∞—á–∏
                if os.path.exists(path):
                    os.unlink(path)

        response = StreamingHttpResponse(
            file_iterator(temp_file_path),
            content_type='application/octet-stream'
        )
        response['Content-Disposition'] = 'attachment; filename="chunk.pickle"'
        return response

    except Exception as e:
        # –£–¥–∞–ª—è–µ–º —Ñ–∞–π–ª —Ç–æ–ª—å–∫–æ –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏
        if os.path.exists(temp_file_path):
            os.unlink(temp_file_path)
        return HttpResponse(f"Error serializing documents: {str(e)}", status=500)


class ChunkListView(LoginRequiredMixin, ListView):
    """–°–ø–∏—Å–∫–æ–≤—ã–π –ø—Ä–æ—Å–º–æ—Ç—Ä —á–∞–Ω–∫–æ–≤"""
    # TODO –ø—Ä–∞–≤–æ –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ –≤–ª–∞–¥–µ–ª—å—Ü–∞
    model = Chunk
    queryset = (Chunk.objects.select_related("author")
                .prefetch_related("embedding__report", "embedding__embedding_engine"))

    def get(self, *args, **kwargs):
        queryset = super().get_queryset()
        url_content_pk = self.request.GET.get("urlcontent")
        cleaned_content_pk = self.request.GET.get("cleanedcontent")
        raw_content_pk = self.request.GET.get("rawcontent")
        if url_content_pk:
            url_content = URLContent.objects.get(pk=url_content_pk)
            document = url_content.url
            storage = document.site
            kb = storage.kb

            queryset = queryset.filter(url_content=url_content)
            context = {
                "content": url_content,
                "content_type_ru": "–ß–∏—Å—Ç—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç",
                "document": document,
                "document_type_ru": "–í–µ–±-—Å—Ç—Ä–∞–Ω–∏—Ü–∞",
                "storage": storage,
                "storage_type_eng": "website",
                "storage_type_ru": "–í–µ–±-—Å–∞–π—Ç",
                "kb": kb,
                "object": url_content,
                "chunk_list": queryset,
            }
        elif cleaned_content_pk:
            cleaned_content = CleanedContent.objects.get(pk=cleaned_content_pk)
            document = cleaned_content.network_document or cleaned_content.local_document
            storage = document.storage
            kb = storage.kb

            queryset = queryset.filter(cleaned_content=cleaned_content)
            context = {
                "content": cleaned_content,
                "content_type_ru": "–ß–∏—Å—Ç—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç",
                "document": document,
                "document_type_ru": "–í–µ–±-—Å—Ç—Ä–∞–Ω–∏—Ü–∞",
                "storage": storage,
                "storage_type_eng": "website",
                "storage_type_ru": "–í–µ–±-—Å–∞–π—Ç",
                "kb": kb,
                # "object": url_content,
                "chunk_list": queryset,
            }

        elif raw_content_pk:
            raw_content = RawContent.objects.get(pk=raw_content_pk)
            document = raw_content.network_document or raw_content.local_document
            storage = document.storage
            kb = storage.kb

            queryset = queryset.filter(raw_content=raw_content)
            context = {
                "content": raw_content,
                "content_type_ru": "–ò—Å—Ö–æ–¥–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç",
                "document": document,
                "document_type_ru": "–°–µ—Ç–µ–≤–æ–π –¥–æ–∫—É–º–µ–Ω—Ç" if raw_content.network_document else "–õ–æ–∫–∞–ª—å–Ω—ã–π –¥–æ–∫—É–º–µ–Ω—Ç",
                "storage": storage,
                "storage_type_eng": "cloud" if raw_content.network_document else "local",
                "storage_type_ru": storage._meta.verbose_name,
                "kb": kb,
                # "object": url_content,
                "chunk_list": queryset,
            }
        else:
            context = {}

        return render(request=self.request, template_name="app_chunks/chunk_list.html", context=context)


class ChunkDetailView(LoginRequiredMixin, DetailView):
    """–î–∞—Ç–µ–ª—å–Ω—ã–π –ø—Ä–æ—Å–º–æ—Ç—Ä Chunk"""
    # TODO –ø—Ä–∞–≤–æ –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ –≤–ª–∞–¥–µ–ª—å—Ü–∞
    model = Chunk


class ChunkCreateFromURLContentView(LoginRequiredMixin, View):
    """–°–æ–∑–¥–∞–Ω–∏–µ —á–∞–Ω–∫–æ–≤ –∏–∑ URLContent"""

    def get(self, request, url_content_pk, *args, **kwargs):
        chunk_preview_set = Prefetch(
            "chunks",
            queryset=Chunk.objects.order_by("pk").only("id", "status", "metadata")[:5],
            to_attr="chunk_preview_set"
        )

        urlcontent_qs = URLContent.objects.select_related("report", "author") \
            .prefetch_related(chunk_preview_set) \
            .annotate(chunks_counter=Count("chunks", distinct=True))

        url_content = get_object_or_404(urlcontent_qs, pk=url_content_pk)
        document = url_content.url
        storage = document.site
        kb = storage.kb
        context = {
            "kb": kb,
            "storage": storage,
            "storage_type_ru": "–í–µ–±-—Å–∞–π—Ç",
            "storage_type_eng": "website",
            "document": document,
            "document_type_ru": "–í–µ–±-—Å—Ç—Ä–∞–Ω–∏—Ü–∞",
            "content": url_content,
            "content_type_ru": "–ß–∏—Å—Ç—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç",
            "object": url_content,
        }
        # —Ñ–æ—Ä–º–∞ –≤—ã–±–æ—Ä–∞ –∫–ª–∞—Å—Å–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞—Ç–µ–ª—è
        dispatcher = SplitterDispatcher()
        splitters = dispatcher.list_all()
        splitter_select_form = SplitterSelectForm(splitters=splitters)
        config_form = SplitterDynamicConfigForm()
        context["form"] = splitter_select_form
        context["config_form"] = config_form
        return render(request, "app_chunks/urlcontent_chunking.html", context)

    def post(self, request, url_content_pk, *args, **kwargs):
        url_content = get_object_or_404(URLContent, pk=url_content_pk)
        document = url_content.url
        storage = document.site
        kb = storage.kb
        context = {
            "content": url_content,
            "document": document,
            "storage": storage,
            "kb": kb,
        }

        dispatcher = SplitterDispatcher()
        splitters = dispatcher.list_all()
        splitter_select_form = SplitterSelectForm(request.POST, splitters=splitters)

        if not splitter_select_form.is_valid():
            context["form"] = splitter_select_form
            context["config_form"] = None
            return render(request, "app_chunks/urlcontent_chunking.html", context)
        splitter_cls = splitter_select_form.cleaned_data.get("splitters")
        splitter_config_schema = getattr(splitter_cls, "config_schema", {})
        config_form = SplitterDynamicConfigForm(request.POST, schema=splitter_config_schema)
        if not config_form.is_valid():
            context["form"] = splitter_select_form
            context["config_form"] = config_form
            return render(request, "app_chunks/urlcontent_chunking.html", context)
        splitter_config = config_form.cleaned_data
        splitter = splitter_cls(splitter_config)

        body = url_content.body
        metadata = url_content.metadata

        url = url_content.url.url
        metadata["url"] = url

        documents = splitter.split(metadata=metadata, text_to_split=body)

        save_documents_to_file(documents, "chunk.pickle")
        bulk_container = []
        for document in documents:
            chunk = Chunk(
                url_content=url_content,
                status=ChunkStatus.READY.value,
                metadata=document.metadata,
                page_content=document.page_content,
                splitter_cls=splitter_cls.__name__,
                splitter_config=splitter_config,
                author=request.user,
            )
            bulk_container.append(chunk)
        if bulk_container:
            Chunk.objects.bulk_create(bulk_container)

        return redirect(reverse_lazy("chunks:chunk_list") + f"?urlcontent={url_content.pk}")


class ChunkCreateFromWebSiteView(LoginRequiredMixin, View):
    """–°–æ–∑–¥–∞–Ω–∏–µ —á–∞–Ω–∫–æ–≤ –∏–∑ URLContent"""

    @staticmethod
    def parse_date_param(param):
        try:
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º ISO-–¥–∞—Ç—É "YYYY-MM-DD" ‚Üí datetime + timezone
            return make_aware(datetime.strptime(param, "%Y-%m-%d"))
        except (ValueError, TypeError):
            return None

    @staticmethod
    def parse_int_param(param):
        try:
            return int(param) if param else None
        except (ValueError, TypeError):
            return None

    def get(self, request, pk):
        storage_qs = WebSite.objects.annotate(
            source_counter=Count("url", distinct=True),
            chunk_counter=Count("url__urlcontent__chunks", distinct=True)
        )
        storage = get_object_or_404(storage_qs, pk=pk)

        kb = storage.kb
        context = {
            "kb": kb,
            "storage": storage,
            "storage_type_ru": "–í–µ–±-—Å–∞–π—Ç",
            "storage_type_eng": "website",
        }

        dispatcher = SplitterDispatcher()
        splitters = dispatcher.list_all()

        current_splitter = storage.configs.get("current_splitter")
        splitter_help = None

        if current_splitter and isinstance(current_splitter, dict):
            # –ü–æ–ª—É—á–∞–µ–º –∏–º—è –∫–ª–∞—Å—Å–∞ –∏ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
            splitter_class_name = current_splitter.get("cls")
            initial_config = current_splitter.get("config", {})

            try:
                # –ü—Ä–æ–±—É–µ–º –ø–æ–ª—É—á–∏—Ç—å –∫–ª–∞—Å—Å –∏ —ç–∫–∑–µ–º–ø–ª—è—Ä —Å–ø–ª–∏—Ç—Ç–µ—Ä–∞
                splitter_cls = dispatcher.get_by_name(splitter_class_name)
                splitter_instance = splitter_cls(initial_config)  # –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤–∞–ª–∏–¥–Ω–æ—Å—Ç–∏
                schema = splitter_cls.config_schema
                splitter_help = getattr(splitter_cls, "help_text", "")

                full_class_name = f"{splitter_cls.__module__}.{splitter_cls.__name__}"
                splitter_select_form = SplitterSelectForm(
                    splitters=splitters,
                    initial={"splitters": full_class_name}
                )

                config_form = SplitterDynamicConfigForm(
                    schema=schema,
                    initial_config=initial_config
                )

            except Exception as e:
                logger.warning(f"–û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ —Ç–µ–∫—É—â–µ–≥–æ —Å–ø–ª–∏—Ç—Ç–µ—Ä–∞ {splitter_class_name}: {e}")
                # fallback –Ω–∞ –ø—É—Å—Ç—É—é —Ñ–æ—Ä–º—É –±–µ–∑ initial
                splitter_select_form = SplitterSelectForm(splitters=splitters)
                config_form = SplitterDynamicConfigForm()

        else:
            # –ï—Å–ª–∏ —Å–ø–ª–∏—Ç—Ç–µ—Ä –Ω–µ –∑–∞–¥–∞–Ω ‚Äî –ø—É—Å—Ç–∞—è —Ñ–æ—Ä–º–∞ –≤—ã–±–æ—Ä–∞
            splitter_select_form = SplitterSelectForm(splitters=splitters)
            config_form = SplitterDynamicConfigForm()

        context["form"] = splitter_select_form
        context["splitter_help"] = splitter_help
        context["config_form"] = config_form
        return render(request, "app_chunks/storage_chunking.html", context)

    def post(self, request, pk):
        export_only_flag = request.POST.get("export_only_flag")
        if not export_only_flag:
            storage_qs = WebSite.objects.annotate(
                source_counter=Count("url", distinct=True),
                chunk_counter=Count("url__urlcontent__chunks", distinct=True)
            )
            storage = get_object_or_404(storage_qs, pk=pk)
            kb = storage.kb
            context = {
                "kb": kb,
                "storage": storage,
                "storage_type_ru": "–í–µ–±-—Å–∞–π—Ç",
                "storage_type_eng": "website",
            }

            dispatcher = SplitterDispatcher()
            splitters = dispatcher.list_all()
            splitter_select_form = SplitterSelectForm(request.POST, splitters=splitters)

            if not splitter_select_form.is_valid():
                context["form"] = splitter_select_form
                context["config_form"] = None
                return render(request, "app_chunks/storage_chunking.html", context)

            splitter_cls = splitter_select_form.cleaned_data.get("splitters")
            splitter_config_schema = getattr(splitter_cls, "config_schema", {})
            splitter_help = getattr(splitter_cls, "help_text", "")

            config_form = SplitterDynamicConfigForm(request.POST, schema=splitter_config_schema)
            if not config_form.is_valid():
                context["form"] = splitter_select_form
                context["config_form"] = config_form
                return render(request, "app_chunks/storage_chunking.html", context)

            splitter_config = config_form.cleaned_data
            # —Ç–µ—Å—Ç–æ–≤–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–ø–ª–∏—Ç—Ç–µ—Ä–∞
            try:
                splitter = splitter_cls(splitter_config)
            except Exception as e:
                splitter_select_form.add_error("splitters", f"–û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ —Å–ø–ª–∏—Ç—Ç–µ—Ä–∞"
                                                            f" {splitter_cls} c –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π {splitter_config}: {e}")
                context["form"] = splitter_select_form
                context["splitter_help"] = splitter_help
                context["config_form"] = config_form
                return render(request, "app_chunks/storage_chunking.html", context)

            url_contents = URLContent.objects.select_related("url").filter(url__site=storage)

            report_content = {
                "initial_data": {
                    "splitter": {
                        "cls": f"{splitter.__module__}.{splitter.__class__.__name__}",
                        "config": splitter.config,
                    },
                    "objects": {
                        "type": "urlcontent",
                        "ids": [url_content.pk for url_content in url_contents],
                    },
                }
            }

            chunking_report = ChunkingReport.objects.create(
                site=storage,
                author=request.user,
                content=report_content,
            )

            task = bulk_chunks_create.delay(
                content_list=url_contents,
                report_pk=chunking_report.pk,
                splitter_cls=splitter_cls,
                splitter_config=splitter_config,
                author_pk=request.user.pk
            )

            chunking_report.running_background_tasks[task.id] = "–°–æ–∑–¥–∞–Ω–∏–µ —á–∞–Ω–∫–æ–≤"
            chunking_report.save(update_fields=["running_background_tasks", ])

            site_splitter_config = {
                "cls": f"{splitter.__module__}.{splitter.__class__.__name__}",
                "config": splitter.config,
            }

            storage.configs["current_splitter"] = site_splitter_config
            storage.save(update_fields=["configs", ])

            context = {
                "kb": kb,
                "task_id": task.id,
                "task_name": f"–ß–∞–Ω–∫–∏–Ω–≥ –≤–µ–±-—Å—Ç—Ä–∞–Ω–∏—Ü —Å–∞–π—Ç–∞ {storage.name}",
                "task_object_url": reverse_lazy("chunks:test_model_report"),
                "task_object_name": "–û—Ç—á–µ—Ç –æ —á–∞–Ω–∫–∏–Ω–≥–µ",
                "next_step_url": reverse_lazy("sources:website_detail", kwargs={"pk": storage.pk}),
            }
            return render(request=request,
                          template_name="celery_task_progress.html",
                          context=context
                          )
        # –≤–∞—Ä–∏–∞–Ω—Ç –¥–ª—è –≤—ã–≥—Ä—É–∑–∫–∏ —á–∞–Ω–∫–æ–≤ –≤ —Ñ–∞–π–ª –∏–∑ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ urlcontent
        website = WebSite.objects.get(pk=pk)
        is_ajax = request.headers.get('X-Requested-With') == 'XMLHttpRequest'

        standard_range_filter = {
            "–¥–∞—Ç–∞ —Å–æ–∑–¥–∞–Ω–∏—è": {
                "type": "date",
                "pairs": (
                    ("created_at__gte", "—Å"),
                    ("created_at__lte", "–ø–æ"),
                ),
            }
        }
        nonstandard_range_filter = {
            "–¥–ª–∏–Ω–∞ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ (—Å–∏–º–≤–æ–ª–æ–≤)": {
                "annotations": {"urlcontent__body_length": Length("urlcontent__body")},
                "type": "number",
                "pairs": (
                    ("urlcontent__body_length__gte", "–æ—Ç"),
                    ("urlcontent__body_length__lte", "–¥–æ"),
                ),
            }
        }

        # –ü–æ–ª—É—á–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∏–∑ POST
        search_query = request.POST.get("search", "").strip()
        status_filter = request.POST.getlist("status", None)
        tags_filter = request.POST.getlist("tags", None)

        urls = website.url_set.all()

        # üîç –ü–æ–∏—Å–∫
        if search_query:
            urls = urls.filter(
                Q(title__icontains=search_query) | Q(url__icontains=search_query)
            )

        # ‚úÖ –°—Ç–∞—Ç—É—Å—ã
        if status_filter:
            valid_statuses = [status.value for status in SourceStatus]
            filtered_statuses = [s for s in status_filter if s in valid_statuses]
            if filtered_statuses:
                urls = urls.filter(status__in=filtered_statuses)

        # üè∑ –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ —Ç–µ–≥–∞–º
        # –í–µ—Ä—Å–∏—è –¥–ª—è PostgreSQL
        # if tags_filter:
        #     # –§–∏–ª—å—Ç—Ä—É–µ–º URL, —É –∫–æ—Ç–æ—Ä—ã—Ö –µ—Å—Ç—å URLContent —Å —É–∫–∞–∑–∞–Ω–Ω—ã–º–∏ —Ç–µ–≥–∞–º–∏
        #     urls = urls.filter(
        #         urlcontent__tags__contains=tags_filter
        #     ).distinct()

        if tags_filter:
            # –ü–æ–ª—É—á–∞–µ–º ID –≤—Å–µ—Ö URLContent, –≥–¥–µ tags —Å–æ–¥–µ—Ä–∂–∞—Ç —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω —Ç–µ–≥ –∏–∑ tags_filter
            urlcontent_ids = URLContent.objects.filter(
                url__site=website
            ).values_list("id", "tags")
            matching_url_ids = set()
            for uc_id, tags in urlcontent_ids:
                if tags and any(tag in tags for tag in tags_filter):
                    url_id = URLContent.objects.get(id=uc_id).url_id
                    matching_url_ids.add(url_id)
            urls = urls.filter(id__in=matching_url_ids).distinct()

        # üìÖ –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –¥–∏–∞–ø–∞–∑–æ–Ω (–¥–∞—Ç—ã)
        standard_range_query = {}
        for group in standard_range_filter.values():
            for param_key, _ in group["pairs"]:
                raw_value = request.POST.get(param_key)
                if raw_value and raw_value.strip():
                    aware_date = self.parse_date_param(raw_value)
                    if aware_date:
                        standard_range_query[param_key] = aware_date
        if standard_range_query:
            urls = urls.filter(**standard_range_query)

        # üîß –ê–Ω–Ω–æ—Ç–∞—Ü–∏–∏ + –Ω–µ—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –¥–∏–∞–ø–∞–∑–æ–Ω (—á–∏—Å–ª–æ–≤—ã–µ)
        combined_annotations = {}
        nonstandard_range_query = {}
        for item in nonstandard_range_filter.values():
            item_annotations = item.get("annotations", {})
            should_add_annotation = False

            for param_key, _ in item["pairs"]:
                val = request.POST.get(param_key)
                if val is not None and val.strip() != "":
                    try:
                        if item["type"] == "number":
                            int_val = self.parse_int_param(val.strip())
                            if int_val is not None:
                                nonstandard_range_query[param_key] = int_val
                                should_add_annotation = True
                    except ValueError:
                        pass

            if should_add_annotation:
                combined_annotations.update(item_annotations)

        if combined_annotations:
            urls = urls.annotate(**combined_annotations)
        if nonstandard_range_query:
            urls = urls.filter(**nonstandard_range_query)

        # –ü–æ–ª—É—á–∞–µ–º —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏–µ URLContent –¥–ª—è –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã—Ö URL
        url_content_qs = URLContent.objects.filter(url_id=OuterRef("id")).order_by("-created_at")[:1]
        urls = urls.prefetch_related(
            Prefetch(
                "urlcontent_set",
                queryset=URLContent.objects.filter(id__in=Subquery(url_content_qs.values("id"))),
                to_attr="related_urlcontents"
            )
        ).annotate(
            urlcontent_total_count=Count("urlcontent")
        )

        # –°–æ–±–∏—Ä–∞–µ–º URLContent
        url_contents = []
        for url in urls:
            if url.related_urlcontents:
                url_contents.append(url.related_urlcontents[0])

        documents = []
        for url_content in url_contents:
            url = url_content.url.url
            # print(url)
            body = url_content.body
            metadata = url_content.metadata
            metadata.pop("internal_links")

            total_header = ""
            if metadata.get("title"):
                total_header += "–ó–∞–≥–æ–ª–æ–≤–æ–∫: " + metadata.get("title") + ". "
            if metadata.get("tags"):
                total_header += "–ö–∞—Ç–µ–≥–æ—Ä–∏–∏: " + ", ".join(metadata.get("tags")) + ". "

            # chunks = split_markdown_text(body)
            source_chunks, fragments = split_text(body, 750)
            for chunk in source_chunks:
                chunk.metadata.update(metadata)
                chunk.metadata["url"] = url

            source_chunks = [process_document(chunk) for chunk in source_chunks]

            for chunk in source_chunks:
                chunk.page_content = total_header + chunk.page_content
                chunk.metadata = flatten_metadata(chunk.metadata)

            documents.extend(source_chunks)

        # save_documents_to_file(documents, "chunk.pickle")
        response = save_documents_to_response(request, documents, is_ajax)
        return response


class ChunkCreateFromStorageView(LoginRequiredMixin, View):
    """–°–æ–∑–¥–∞–Ω–∏–µ —á–∞–Ω–∫–æ–≤ –∏–∑ –•—Ä–∞–Ω–∏–ª–∏—â–∞ Storage (CloudStorage, LocalStorage)"""
    STORAGES = {
        "cloud": CloudStorage,
        "Local": LocalStorage,
        "website": WebSite,
        "urlbatch": URLBatch,
    }

    def get(self, request, storage_type, storage_pk):

        storage_cls = self.STORAGES.get(storage_type)
        if not storage_cls:
            return HttpResponse(404)

        storage_qs = storage_cls.objects.annotate(
            source_counter=Count("documents", distinct=True),
            raw_chunks_count=Count("documents__rawcontent__chunks", distinct=True),
            cleaned_chunks_count=Count("documents__cleanedcontent__chunks", distinct=True)
        ).annotate(
            chunk_counter=ExpressionWrapper(
                F("raw_chunks_count") + F("cleaned_chunks_count"),
                output_field=IntegerField()
            )
        )
        storage = get_object_or_404(storage_qs, pk=storage_pk)

        kb = storage.kb
        context = {
            "kb": kb,
            "storage": storage,
            "storage_type_ru": storage_cls._meta.verbose_name,
            "storage_type_eng": storage_type,
        }

        dispatcher = SplitterDispatcher()
        splitters = dispatcher.list_all()

        current_splitter = storage.configs.get("current_splitter")
        splitter_help = None

        if current_splitter and isinstance(current_splitter, dict):
            # –ü–æ–ª—É—á–∞–µ–º –∏–º—è –∫–ª–∞—Å—Å–∞ –∏ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
            splitter_class_name = current_splitter.get("cls")
            initial_config = current_splitter.get("config", {})

            try:
                # –ü—Ä–æ–±—É–µ–º –ø–æ–ª—É—á–∏—Ç—å –∫–ª–∞—Å—Å –∏ —ç–∫–∑–µ–º–ø–ª—è—Ä —Å–ø–ª–∏—Ç—Ç–µ—Ä–∞
                splitter_cls = dispatcher.get_by_name(splitter_class_name)
                splitter_instance = splitter_cls(initial_config)  # –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤–∞–ª–∏–¥–Ω–æ—Å—Ç–∏
                splitter_help = getattr(splitter_cls, "help_text", "")
                schema = splitter_cls.config_schema

                full_class_name = f"{splitter_cls.__module__}.{splitter_cls.__name__}"
                splitter_select_form = SplitterSelectForm(
                    splitters=splitters,
                    initial={"splitters": full_class_name}
                )

                config_form = SplitterDynamicConfigForm(
                    schema=schema,
                    initial_config=initial_config
                )

            except Exception as e:
                logger.warning(f"–û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ —Ç–µ–∫—É—â–µ–≥–æ —Å–ø–ª–∏—Ç—Ç–µ—Ä–∞ {splitter_class_name}: {e}")
                # fallback –Ω–∞ –ø—É—Å—Ç—É—é —Ñ–æ—Ä–º—É –±–µ–∑ initial
                splitter_select_form = SplitterSelectForm(splitters=splitters)
                config_form = None

        else:
            # –ï—Å–ª–∏ —Å–ø–ª–∏—Ç—Ç–µ—Ä –Ω–µ –∑–∞–¥–∞–Ω ‚Äî –ø—É—Å—Ç–∞—è —Ñ–æ—Ä–º–∞ –≤—ã–±–æ—Ä–∞
            splitter_select_form = SplitterSelectForm(splitters=splitters)
            config_form = None

        context["form"] = splitter_select_form
        context["splitter_help"] = splitter_help
        context["config_form"] = config_form
        return render(request, "app_chunks/storage_chunking.html", context)

    def post(self, request, storage_type, storage_pk):
        storage_cls = self.STORAGES.get(storage_type)
        if not storage_cls:
            return HttpResponse(404)

        storage_qs = storage_cls.objects.annotate(
            source_counter=Count("documents", distinct=True),
            raw_chunks_count=Count("documents__rawcontent__chunks", distinct=True),
            cleaned_chunks_count=Count("documents__cleanedcontent__chunks", distinct=True)
        ).annotate(
            chunk_counter=ExpressionWrapper(
                F("raw_chunks_count") + F("cleaned_chunks_count"),
                output_field=IntegerField()
            )
        )
        storage = get_object_or_404(storage_qs, pk=storage_pk)

        kb = storage.kb
        context = {
            "kb": kb,
            "storage": storage,
            "storage_type_ru": storage_cls._meta.verbose_name,
            "storage_type_eng": storage_type,
        }

        dispatcher = SplitterDispatcher()
        splitters = dispatcher.list_all()
        splitter_select_form = SplitterSelectForm(request.POST, splitters=splitters)

        if not splitter_select_form.is_valid():
            context["form"] = splitter_select_form
            context["config_form"] = None
            return render(request, "app_chunks/storage_chunking.html", context)

        splitter_cls = splitter_select_form.cleaned_data.get("splitters")
        splitter_config_schema = getattr(splitter_cls, "config_schema", {})
        splitter_help = getattr(splitter_cls, "help_text", "")
        config_form = SplitterDynamicConfigForm(request.POST, schema=splitter_config_schema)

        if not config_form.is_valid():
            context["form"] = splitter_select_form
            context["splitter_help"] = splitter_help
            context["config_form"] = config_form
            return render(request, "app_chunks/storage_chunking.html", context)
        splitter_config = config_form.cleaned_data
        # —Ç–µ—Å—Ç–æ–≤–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–ø–ª–∏—Ç—Ç–µ—Ä–∞
        try:
            splitter = splitter_cls(splitter_config)
        except Exception as e:
            splitter_select_form.add_error("splitters", f"–û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ —Å–ø–ª–∏—Ç—Ç–µ—Ä–∞"
                                                        f" {splitter_cls} c –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π {splitter_config}: {e}")
            context["form"] = splitter_select_form
            context["splitter_help"] = splitter_help
            context["config_form"] = config_form
            return render(request, "app_chunks/storage_chunking.html", context)

        # TODO –¥–æ–ø–æ–ª–Ω–∏—Ç—å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—é —Å—Ç–∞—Ç—É—Å–æ–≤
        raw_content_qs = RawContent.objects.filter(
            status=ContentStatus.READY.value
        ).select_related(
            'cleanedcontent'
        ).order_by("-created_at")[:1]

        raw_content_active = Prefetch("rawcontent_set", queryset=raw_content_qs, to_attr='related_rawcontents')

        documents = (storage.documents.prefetch_related(raw_content_active)
                     .exclude(status=SourceStatus.EXCLUDED.value))
        for doc in documents:
            doc.active_raw_content = doc.related_rawcontents[0] if doc.related_rawcontents else None
            if doc.active_raw_content and doc.active_raw_content.file:
                doc.file_get_url = request.build_absolute_uri(doc.active_raw_content.file.url)
            else:
                doc.file_get_url = None

        report_content = {
            "initial_data": {
                "splitter": {
                    "cls": f"{splitter.__module__}.{splitter.__class__.__name__}",
                    "config": splitter.config,
                },
                "objects": {
                    "type": f"{storage_type} documents",
                    "ids": [document.pk for document in documents],
                },
            }
        }

        chunking_report = ChunkingReport(
            author=request.user,
            content=report_content,
        )
        if isinstance(storage, CloudStorage):
            chunking_report.cloud_storage = storage
        elif isinstance(storage, LocalStorage):
            chunking_report.local_storage = storage
        elif isinstance(storage, WebSite):
            chunking_report.site = storage
        elif isinstance(storage, URLBatch):
            chunking_report.batch = storage
        chunking_report.save()

        task = universal_bulk_chunks_create.delay(
            sources_list=documents,
            report_pk=chunking_report.pk,
            splitter_cls=splitter_cls,
            splitter_config=splitter_config,
            author_pk=request.user.pk
        )

        chunking_report.running_background_tasks[task.id] = "–°–æ–∑–¥–∞–Ω–∏–µ —á–∞–Ω–∫–æ–≤"
        chunking_report.save(update_fields=["running_background_tasks", ])

        splitter_config = {
            "cls": f"{splitter.__module__}.{splitter.__class__.__name__}",
            "config": splitter.config,
        }

        storage.configs["current_splitter"] = splitter_config
        storage.save(update_fields=["configs", ])

        context = {
            "kb": kb,
            "task_id": task.id,
            "task_name": f"–ß–∞–Ω–∫–∏–Ω–≥ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞ {storage_cls._meta.verbose_name}",
            "task_object_url": storage.get_absolute_url(),  # TODO –ü–æ–º–µ–Ω—è—Ç—å –Ω–∞ –≤—ã–≤–æ–¥ –æ—Ç—á–µ—Ç–∞
            "task_object_name": "–û—Ç—á–µ—Ç –æ —á–∞–Ω–∫–∏–Ω–≥–µ",
            "next_step_url": storage.get_absolute_url(),  # TODO –ü–æ–º–µ–Ω—è—Ç—å –Ω–∞ –≤—ã–≤–æ–¥ –æ—Ç—á–µ—Ç–∞
        }
        return render(request=request,
                      template_name="celery_task_progress.html",
                      context=context
                      )
